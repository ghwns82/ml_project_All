{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938fe387",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T05:47:34.621117Z",
     "start_time": "2022-12-19T05:47:34.614350Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c02752",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T05:47:36.705685Z",
     "start_time": "2022-12-19T05:47:34.623181Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 14:47:34.628536: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-19 14:47:34.816969: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-19 14:47:34.817018: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-19 14:47:35.579961: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-19 14:47:35.580258: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-19 14:47:35.580287: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# 경로 참 더럽네\n",
    "from CRNNKerasmaster.parameter import *\n",
    "from CRNNKerasmaster.Model import get_Model\n",
    "from CRNNKerasmaster.Image_Generator import TextImageGenerator\n",
    "\n",
    "import cv2\n",
    "import itertools, os, time\n",
    "import numpy as np\n",
    "import argparse\n",
    "import easydict\n",
    "from datetime import datetime\n",
    "\n",
    "K.set_learning_phase(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9efb63c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T05:47:37.760992Z",
     "start_time": "2022-12-19T05:47:36.707269Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 14:47:36.720052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ghwns82/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-12-19 14:47:36.720112: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-19 14:47:36.720182: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-HN4KDSG): /proc/driver/nvidia/version does not exist\n",
      "2022-12-19 14:47:36.720498: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = get_Model(training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39165317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T05:47:37.766436Z",
     "start_time": "2022-12-19T05:47:37.762703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...New weight data...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.load_weights('LSTM+BN4--26--0.011.hdf5')\n",
    "    print(\"...Previous weight data...\")\n",
    "except:\n",
    "    print(\"...New weight data...\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ced08b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T05:47:37.778786Z",
     "start_time": "2022-12-19T05:47:37.769170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9  Image Loading start...\n",
      "True\n",
      "9  Image Loading finish...\n"
     ]
    }
   ],
   "source": [
    "train_file_path = './CRNNKerasmaster/DB/train/'\n",
    "tiger_train = TextImageGenerator(train_file_path, img_w, img_h, batch_size, downsample_factor)\n",
    "tiger_train.build_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f320856",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T05:47:37.785496Z",
     "start_time": "2022-12-19T05:47:37.779713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  Image Loading start...\n",
      "True\n",
      "5  Image Loading finish...\n"
     ]
    }
   ],
   "source": [
    "valid_file_path = './CRNNKerasmaster/DB/test/'\n",
    "tiger_val = TextImageGenerator(valid_file_path, img_w, img_h, val_batch_size, downsample_factor)\n",
    "tiger_val.build_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a787459c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T05:47:37.788805Z",
     "start_time": "2022-12-19T05:47:37.786723Z"
    }
   },
   "outputs": [],
   "source": [
    "# tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b20e6b14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T05:56:46.144592Z",
     "start_time": "2022-12-19T05:47:37.790620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/1200\n",
      "WARNING:tensorflow:From /home/ghwns82/.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "1/1 [==============================] - 6s 6s/step - loss: 91.0585 - val_loss: 95.1287\n",
      "Epoch 2/1200\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 84.4175 - val_loss: 95.5598\n",
      "Epoch 3/1200\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 87.4812 - val_loss: 93.7206\n",
      "Epoch 4/1200\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 92.2587 - val_loss: 93.5795\n",
      "Epoch 5/1200\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 87.7221 - val_loss: 94.8889\n",
      "Epoch 6/1200\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 90.7402 - val_loss: 94.6604\n",
      "Epoch 7/1200\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 79.5205 - val_loss: 95.0010\n",
      "Epoch 8/1200\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 83.5058 - val_loss: 96.4965\n",
      "Epoch 9/1200\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 77.7922 - val_loss: 94.6896\n",
      "Epoch 10/1200\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 77.8733 - val_loss: 94.6391\n",
      "Epoch 11/1200\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 76.6151 - val_loss: 95.2379\n",
      "Epoch 12/1200\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 74.1456 - val_loss: 95.0509\n",
      "Epoch 13/1200\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 78.2726 - val_loss: 92.8248\n",
      "Epoch 14/1200\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 85.4756 - val_loss: 94.1935\n",
      "Epoch 15/1200\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 75.5159 - val_loss: 94.4751\n",
      "Epoch 16/1200\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 69.4633 - val_loss: 95.3569\n",
      "Epoch 17/1200\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 75.2916 - val_loss: 92.1621\n",
      "Epoch 18/1200\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 81.3568 - val_loss: 94.4726\n",
      "Epoch 19/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 65.2946 - val_loss: 94.9337\n",
      "Epoch 20/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 66.7105 - val_loss: 94.5377\n",
      "Epoch 21/1200\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 65.4131 - val_loss: 94.5713\n",
      "Epoch 22/1200\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 61.3554 - val_loss: 94.6818\n",
      "Epoch 23/1200\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 76.9009 - val_loss: 93.5720\n",
      "Epoch 24/1200\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 69.6896 - val_loss: 96.3917\n",
      "Epoch 25/1200\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 64.3219 - val_loss: 94.6912\n",
      "Epoch 26/1200\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 75.7533 - val_loss: 95.8359\n",
      "Epoch 27/1200\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 67.4031 - val_loss: 97.0039\n",
      "Epoch 28/1200\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 59.1933 - val_loss: 94.3208\n",
      "Epoch 29/1200\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 57.5542 - val_loss: 97.1528\n",
      "Epoch 30/1200\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 66.0299 - val_loss: 95.0247\n",
      "Epoch 31/1200\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 64.0081 - val_loss: 95.9394\n",
      "Epoch 32/1200\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 75.2843 - val_loss: 92.3113\n",
      "Epoch 33/1200\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 85.5117 - val_loss: 95.1969\n",
      "Epoch 34/1200\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 68.3170 - val_loss: 95.3000\n",
      "Epoch 35/1200\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 69.3618 - val_loss: 95.3485\n",
      "Epoch 36/1200\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 61.2783 - val_loss: 96.9166\n",
      "Epoch 37/1200\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 56.6552 - val_loss: 96.1108\n",
      "Epoch 38/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 57.8568 - val_loss: 94.3081\n",
      "Epoch 39/1200\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 66.6292 - val_loss: 96.5258\n",
      "Epoch 40/1200\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 57.3214 - val_loss: 95.4602\n",
      "Epoch 41/1200\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 63.0839 - val_loss: 96.1022\n",
      "Epoch 42/1200\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 65.5805 - val_loss: 95.2331\n",
      "Epoch 43/1200\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 56.3789 - val_loss: 95.4420\n",
      "Epoch 44/1200\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 55.0870 - val_loss: 97.4521\n",
      "Epoch 45/1200\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 56.1274 - val_loss: 95.3755\n",
      "Epoch 46/1200\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 48.9052 - val_loss: 95.3361\n",
      "Epoch 47/1200\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 47.7252 - val_loss: 96.5365\n",
      "Epoch 48/1200\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 62.0491 - val_loss: 93.9439\n",
      "Epoch 49/1200\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 59.6351 - val_loss: 95.0976\n",
      "Epoch 50/1200\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 54.9468 - val_loss: 95.0111\n",
      "Epoch 51/1200\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 52.1543 - val_loss: 94.5268\n",
      "Epoch 52/1200\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 45.4685 - val_loss: 95.8746\n",
      "Epoch 53/1200\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 52.0426 - val_loss: 92.5299\n",
      "Epoch 54/1200\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 51.3515 - val_loss: 95.1205\n",
      "Epoch 55/1200\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 50.2134 - val_loss: 94.6383\n",
      "Epoch 56/1200\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 44.6426 - val_loss: 96.6551\n",
      "Epoch 57/1200\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 52.1883 - val_loss: 95.0646\n",
      "Epoch 58/1200\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 47.1059 - val_loss: 91.6339\n",
      "Epoch 59/1200\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 51.9311 - val_loss: 94.8959\n",
      "Epoch 60/1200\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 60.0017 - val_loss: 94.0674\n",
      "Epoch 61/1200\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 52.7579 - val_loss: 92.7435\n",
      "Epoch 62/1200\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 48.1934 - val_loss: 93.8779\n",
      "Epoch 63/1200\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 46.6739 - val_loss: 93.6614\n",
      "Epoch 64/1200\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 41.6808 - val_loss: 93.5277\n",
      "Epoch 65/1200\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 42.8521 - val_loss: 93.4302\n",
      "Epoch 66/1200\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 43.8256 - val_loss: 92.5559\n",
      "Epoch 67/1200\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 48.4226 - val_loss: 91.9129\n",
      "Epoch 68/1200\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 45.7710 - val_loss: 95.1441\n",
      "Epoch 69/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 46.2053 - val_loss: 91.3717\n",
      "Epoch 70/1200\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 51.7020 - val_loss: 92.8465\n",
      "Epoch 71/1200\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 44.6278 - val_loss: 91.2625\n",
      "Epoch 72/1200\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 40.1709 - val_loss: 92.5738\n",
      "Epoch 73/1200\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 40.6450 - val_loss: 90.3982\n",
      "Epoch 74/1200\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 40.3829 - val_loss: 90.2216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/1200\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 41.6031 - val_loss: 92.2063\n",
      "Epoch 76/1200\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 39.9811 - val_loss: 95.1470\n",
      "Epoch 77/1200\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 41.6445 - val_loss: 92.5651\n",
      "Epoch 78/1200\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 47.9467 - val_loss: 88.8161\n",
      "Epoch 79/1200\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 68.8000 - val_loss: 91.2300\n",
      "Epoch 80/1200\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 53.3389 - val_loss: 91.5398\n",
      "Epoch 81/1200\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 44.6957 - val_loss: 91.4620\n",
      "Epoch 82/1200\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 37.7945 - val_loss: 91.3362\n",
      "Epoch 83/1200\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 35.4569 - val_loss: 91.1832\n",
      "Epoch 84/1200\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 36.3263 - val_loss: 90.6317\n",
      "Epoch 85/1200\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 56.6623 - val_loss: 91.0369\n",
      "Epoch 86/1200\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 73.1015 - val_loss: 90.8654\n",
      "Epoch 87/1200\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 55.7887 - val_loss: 89.0881\n",
      "Epoch 88/1200\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 54.4249 - val_loss: 89.3061\n",
      "Epoch 89/1200\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 54.8681 - val_loss: 90.3830\n",
      "Epoch 90/1200\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 40.9817 - val_loss: 90.3027\n",
      "Epoch 91/1200\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 35.4660 - val_loss: 88.8770\n",
      "Epoch 92/1200\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 38.9903 - val_loss: 86.6048\n",
      "Epoch 93/1200\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 41.2572 - val_loss: 91.8320\n",
      "Epoch 94/1200\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 38.9300 - val_loss: 90.6658\n",
      "Epoch 95/1200\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 51.3787 - val_loss: 89.8225\n",
      "Epoch 96/1200\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 53.5583 - val_loss: 89.2620\n",
      "Epoch 97/1200\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 41.4770 - val_loss: 89.6243\n",
      "Epoch 98/1200\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 46.1804 - val_loss: 90.4083\n",
      "Epoch 99/1200\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 50.5812 - val_loss: 88.5702\n",
      "Epoch 100/1200\n",
      "1/1 [==============================] - ETA: 0s - loss: 37.0900\n",
      "Epoch 100: saving model to LSTM+BN5--2022_12_19_14_47_37.hdf5\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 37.0900 - val_loss: 89.2983\n",
      "Epoch 101/1200\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 32.9911 - val_loss: 87.9871\n",
      "Epoch 102/1200\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 53.7836 - val_loss: 89.0498\n",
      "Epoch 103/1200\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 44.3035 - val_loss: 91.7048\n",
      "Epoch 104/1200\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 37.0019 - val_loss: 88.8855\n",
      "Epoch 105/1200\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 40.9668 - val_loss: 88.7230\n",
      "Epoch 106/1200\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 46.1397 - val_loss: 85.7969\n",
      "Epoch 107/1200\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 33.5719 - val_loss: 88.4594\n",
      "Epoch 108/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 42.3149 - val_loss: 88.3642\n",
      "Epoch 109/1200\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 33.0161 - val_loss: 88.2466\n",
      "Epoch 110/1200\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 31.4006 - val_loss: 88.1113\n",
      "Epoch 111/1200\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 42.4226 - val_loss: 90.7512\n",
      "Epoch 112/1200\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 45.2882 - val_loss: 84.7488\n",
      "Epoch 113/1200\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 36.9613 - val_loss: 88.8672\n",
      "Epoch 114/1200\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 36.7529 - val_loss: 85.9298\n",
      "Epoch 115/1200\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 33.8152 - val_loss: 87.3381\n",
      "Epoch 116/1200\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 32.7747 - val_loss: 90.4378\n",
      "Epoch 117/1200\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 33.1797 - val_loss: 83.2160\n",
      "Epoch 118/1200\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 34.6414 - val_loss: 86.7416\n",
      "Epoch 119/1200\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 32.6433 - val_loss: 88.6099\n",
      "Epoch 120/1200\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 29.7421 - val_loss: 86.5737\n",
      "Epoch 121/1200\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 40.1557 - val_loss: 87.6052\n",
      "Epoch 122/1200\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 35.2803 - val_loss: 87.8298\n",
      "Epoch 123/1200\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 42.7311 - val_loss: 84.2833\n",
      "Epoch 124/1200\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 58.9050 - val_loss: 89.5294\n",
      "Epoch 125/1200\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 38.8412 - val_loss: 85.5709\n",
      "Epoch 126/1200\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 33.4112 - val_loss: 81.5894\n",
      "Epoch 127/1200\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 31.0007 - val_loss: 88.4261\n",
      "Epoch 128/1200\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 32.8188 - val_loss: 85.3243\n",
      "Epoch 129/1200\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 42.2416 - val_loss: 81.5395\n",
      "Epoch 130/1200\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 36.6113 - val_loss: 84.7303\n",
      "Epoch 131/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 42.8372 - val_loss: 81.9101\n",
      "Epoch 132/1200\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 47.5412 - val_loss: 81.1602\n",
      "Epoch 133/1200\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 32.2070 - val_loss: 85.3659\n",
      "Epoch 134/1200\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 34.1351 - val_loss: 83.9283\n",
      "Epoch 135/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 33.4263 - val_loss: 83.7650\n",
      "Epoch 136/1200\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 30.6065 - val_loss: 84.9046\n",
      "Epoch 137/1200\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 31.8033 - val_loss: 81.8045\n",
      "Epoch 138/1200\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 31.6546 - val_loss: 87.4999\n",
      "Epoch 139/1200\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 27.1814 - val_loss: 83.0645\n",
      "Epoch 140/1200\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 33.8424 - val_loss: 82.9275\n",
      "Epoch 141/1200\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 29.6967 - val_loss: 82.7265\n",
      "Epoch 142/1200\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 43.6788 - val_loss: 82.4270\n",
      "Epoch 143/1200\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 28.8543 - val_loss: 80.5471\n",
      "Epoch 144/1200\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 26.9649 - val_loss: 86.3258\n",
      "Epoch 145/1200\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 30.7706 - val_loss: 81.8726\n",
      "Epoch 146/1200\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 28.2756 - val_loss: 81.6669\n",
      "Epoch 147/1200\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 32.3257 - val_loss: 79.1716\n",
      "Epoch 148/1200\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 29.8442 - val_loss: 83.6234\n",
      "Epoch 149/1200\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 50.7753 - val_loss: 80.9381\n",
      "Epoch 150/1200\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 35.5151 - val_loss: 80.7130\n",
      "Epoch 151/1200\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 33.1158 - val_loss: 75.8520\n",
      "Epoch 152/1200\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 29.3716 - val_loss: 84.8152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/1200\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 30.9757 - val_loss: 75.5985\n",
      "Epoch 154/1200\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 27.4325 - val_loss: 81.3827\n",
      "Epoch 155/1200\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 26.8568 - val_loss: 79.7035\n",
      "Epoch 156/1200\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 29.8708 - val_loss: 76.3219\n",
      "Epoch 157/1200\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 26.8639 - val_loss: 78.4541\n",
      "Epoch 158/1200\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 39.5735 - val_loss: 85.3008\n",
      "Epoch 159/1200\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 52.1363 - val_loss: 76.1846\n",
      "Epoch 160/1200\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 34.3716 - val_loss: 78.4444\n",
      "Epoch 161/1200\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 31.4399 - val_loss: 75.8232\n",
      "Epoch 162/1200\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 46.7506 - val_loss: 73.6614\n",
      "Epoch 163/1200\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 26.1351 - val_loss: 77.8286\n",
      "Epoch 164/1200\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 25.8587 - val_loss: 77.6375\n",
      "Epoch 165/1200\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 27.1125 - val_loss: 77.4055\n",
      "Epoch 166/1200\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 31.6604 - val_loss: 75.6775\n",
      "Epoch 167/1200\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 29.7756 - val_loss: 72.0567\n",
      "Epoch 168/1200\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 31.3453 - val_loss: 81.5913\n",
      "Epoch 169/1200\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 27.8891 - val_loss: 73.5326\n",
      "Epoch 170/1200\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 27.5669 - val_loss: 76.1426\n",
      "Epoch 171/1200\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 30.1935 - val_loss: 78.7927\n",
      "Epoch 172/1200\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 23.9700 - val_loss: 76.0278\n",
      "Epoch 173/1200\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 24.7521 - val_loss: 78.3899\n",
      "Epoch 174/1200\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 26.1568 - val_loss: 80.3888\n",
      "Epoch 175/1200\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 44.5442 - val_loss: 74.9966\n",
      "Epoch 176/1200\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 34.8291 - val_loss: 79.9047\n",
      "Epoch 177/1200\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 45.7126 - val_loss: 74.1582\n",
      "Epoch 178/1200\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 32.8576 - val_loss: 71.0873\n",
      "Epoch 179/1200\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 26.2194 - val_loss: 71.5697\n",
      "Epoch 180/1200\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 26.0478 - val_loss: 73.5629\n",
      "Epoch 181/1200\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 27.0174 - val_loss: 72.6018\n",
      "Epoch 182/1200\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 24.4774 - val_loss: 68.0326\n",
      "Epoch 183/1200\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 26.2684 - val_loss: 78.0330\n",
      "Epoch 184/1200\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 41.6346 - val_loss: 76.1449\n",
      "Epoch 185/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 30.7999 - val_loss: 72.1127\n",
      "Epoch 186/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 35.4889 - val_loss: 73.4111\n",
      "Epoch 187/1200\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 27.9582 - val_loss: 67.3811\n",
      "Epoch 188/1200\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 31.4361 - val_loss: 74.3058\n",
      "Epoch 189/1200\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 25.6255 - val_loss: 69.3281\n",
      "Epoch 190/1200\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 22.9128 - val_loss: 70.6902\n",
      "Epoch 191/1200\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 23.6491 - val_loss: 70.4084\n",
      "Epoch 192/1200\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 26.8403 - val_loss: 65.3902\n",
      "Epoch 193/1200\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 39.4770 - val_loss: 70.8652\n",
      "Epoch 194/1200\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 26.4028 - val_loss: 70.1906\n",
      "Epoch 195/1200\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 34.5639 - val_loss: 69.2242\n",
      "Epoch 196/1200\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 29.0484 - val_loss: 68.1152\n",
      "Epoch 197/1200\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 40.1687 - val_loss: 71.7376\n",
      "Epoch 198/1200\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 24.6853 - val_loss: 65.6846\n",
      "Epoch 199/1200\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 23.1302 - val_loss: 67.0444\n",
      "Epoch 200/1200\n",
      "1/1 [==============================] - ETA: 0s - loss: 22.7501\n",
      "Epoch 200: saving model to LSTM+BN5--2022_12_19_14_47_37.hdf5\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 22.7501 - val_loss: 67.6085\n",
      "Epoch 201/1200\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 26.4091 - val_loss: 66.5280\n",
      "Epoch 202/1200\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 25.6193 - val_loss: 64.8710\n",
      "Epoch 203/1200\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 24.2668 - val_loss: 70.0230\n",
      "Epoch 204/1200\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 33.5117 - val_loss: 60.8621\n",
      "Epoch 205/1200\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 21.7529 - val_loss: 66.2744\n",
      "Epoch 206/1200\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 31.7214 - val_loss: 64.4494\n",
      "Epoch 207/1200\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 25.9743 - val_loss: 68.6859\n",
      "Epoch 208/1200\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 22.2234 - val_loss: 64.3677\n",
      "Epoch 209/1200\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 24.4901 - val_loss: 64.9577\n",
      "Epoch 210/1200\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 23.3579 - val_loss: 64.5939\n",
      "Epoch 211/1200\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 24.8259 - val_loss: 68.3198\n",
      "Epoch 212/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 31.2421 - val_loss: 70.2536\n",
      "Epoch 213/1200\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 23.6079 - val_loss: 56.9786\n",
      "Epoch 214/1200\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 22.2599 - val_loss: 64.1527\n",
      "Epoch 215/1200\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 25.6530 - val_loss: 63.0060\n",
      "Epoch 216/1200\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 21.6890 - val_loss: 63.4852\n",
      "Epoch 217/1200\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 21.5655 - val_loss: 61.2633\n",
      "Epoch 218/1200\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 21.4144 - val_loss: 63.5474\n",
      "Epoch 219/1200\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 23.8481 - val_loss: 55.8413\n",
      "Epoch 220/1200\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 22.8839 - val_loss: 61.3241\n",
      "Epoch 221/1200\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 20.1522 - val_loss: 60.9687\n",
      "Epoch 222/1200\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 29.7479 - val_loss: 54.7751\n",
      "Epoch 223/1200\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 25.0227 - val_loss: 62.1323\n",
      "Epoch 224/1200\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 25.9128 - val_loss: 60.7918\n",
      "Epoch 225/1200\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 20.1466 - val_loss: 59.5831\n",
      "Epoch 226/1200\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 22.4167 - val_loss: 61.1957\n",
      "Epoch 227/1200\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 22.1611 - val_loss: 62.8211\n",
      "Epoch 228/1200\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 22.8010 - val_loss: 54.6688\n",
      "Epoch 229/1200\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 26.2957 - val_loss: 58.2396\n",
      "Epoch 230/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 400ms/step - loss: 25.1995 - val_loss: 57.9504\n",
      "Epoch 231/1200\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 26.3250 - val_loss: 54.9945\n",
      "Epoch 232/1200\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 26.9946 - val_loss: 56.1473\n",
      "Epoch 233/1200\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 28.3315 - val_loss: 60.6331\n",
      "Epoch 234/1200\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 22.6394 - val_loss: 52.7007\n",
      "Epoch 235/1200\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 21.7352 - val_loss: 56.1246\n",
      "Epoch 236/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 19.3523 - val_loss: 50.1631\n",
      "Epoch 237/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 39.6824 - val_loss: 61.0105\n",
      "Epoch 238/1200\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 19.6125 - val_loss: 58.1193\n",
      "Epoch 239/1200\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 30.8720 - val_loss: 51.0220\n",
      "Epoch 240/1200\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 33.9369 - val_loss: 54.1004\n",
      "Epoch 241/1200\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 19.8679 - val_loss: 53.7054\n",
      "Epoch 242/1200\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 23.9674 - val_loss: 50.5676\n",
      "Epoch 243/1200\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 19.6522 - val_loss: 52.3827\n",
      "Epoch 244/1200\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 19.0866 - val_loss: 52.7969\n",
      "Epoch 245/1200\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 19.2974 - val_loss: 52.4253\n",
      "Epoch 246/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 18.4501 - val_loss: 55.5205\n",
      "Epoch 247/1200\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 43.3073 - val_loss: 51.6400\n",
      "Epoch 248/1200\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 30.1408 - val_loss: 51.8720\n",
      "Epoch 249/1200\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 26.1808 - val_loss: 52.6688\n",
      "Epoch 250/1200\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 28.9988 - val_loss: 50.4908\n",
      "Epoch 251/1200\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 40.8614 - val_loss: 49.4070\n",
      "Epoch 252/1200\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 18.1991 - val_loss: 46.6928\n",
      "Epoch 253/1200\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 18.4865 - val_loss: 51.9234\n",
      "Epoch 254/1200\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 20.2980 - val_loss: 48.5190\n",
      "Epoch 255/1200\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 21.0488 - val_loss: 48.9430\n",
      "Epoch 256/1200\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 26.2825 - val_loss: 50.9625\n",
      "Epoch 257/1200\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 23.0259 - val_loss: 45.5553\n",
      "Epoch 258/1200\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 28.5631 - val_loss: 47.7014\n",
      "Epoch 259/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 22.3902 - val_loss: 45.0420\n",
      "Epoch 260/1200\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 18.2673 - val_loss: 47.1258\n",
      "Epoch 261/1200\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 21.0291 - val_loss: 46.5412\n",
      "Epoch 262/1200\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 17.7853 - val_loss: 43.6646\n",
      "Epoch 263/1200\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 17.9326 - val_loss: 43.8608\n",
      "Epoch 264/1200\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 35.5285 - val_loss: 45.7833\n",
      "Epoch 265/1200\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 17.2916 - val_loss: 45.4615\n",
      "Epoch 266/1200\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 20.8890 - val_loss: 45.5030\n",
      "Epoch 267/1200\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 29.5831 - val_loss: 44.5500\n",
      "Epoch 268/1200\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 32.8421 - val_loss: 47.9559\n",
      "Epoch 269/1200\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 39.9653 - val_loss: 43.6138\n",
      "Epoch 270/1200\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 24.1031 - val_loss: 43.4411\n",
      "Epoch 271/1200\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 16.9828 - val_loss: 43.1200\n",
      "Epoch 272/1200\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 16.7959 - val_loss: 46.8955\n",
      "Epoch 273/1200\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 19.1318 - val_loss: 40.3129\n",
      "Epoch 274/1200\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 20.3351 - val_loss: 43.9096\n",
      "Epoch 275/1200\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 23.7588 - val_loss: 41.8276\n",
      "Epoch 276/1200\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 20.5785 - val_loss: 39.1498\n",
      "Epoch 277/1200\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 40.7879 - val_loss: 41.1451\n",
      "Epoch 278/1200\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 28.9323 - val_loss: 38.9565\n",
      "Epoch 279/1200\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 21.4899 - val_loss: 39.9730\n",
      "Epoch 280/1200\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 16.4335 - val_loss: 40.0795\n",
      "Epoch 281/1200\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 16.2552 - val_loss: 39.4067\n",
      "Epoch 282/1200\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 19.7057 - val_loss: 39.5570\n",
      "Epoch 283/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 21.1575 - val_loss: 41.3289\n",
      "Epoch 284/1200\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 30.7322 - val_loss: 38.8509\n",
      "Epoch 285/1200\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 21.6275 - val_loss: 38.5795\n",
      "Epoch 286/1200\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 26.3324 - val_loss: 38.4344\n",
      "Epoch 287/1200\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 16.7021 - val_loss: 36.5681\n",
      "Epoch 288/1200\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 17.1097 - val_loss: 35.8925\n",
      "Epoch 289/1200\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 16.4611 - val_loss: 39.6485\n",
      "Epoch 290/1200\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 16.3781 - val_loss: 37.3062\n",
      "Epoch 291/1200\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 19.7737 - val_loss: 34.9499\n",
      "Epoch 292/1200\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 16.1970 - val_loss: 37.0195\n",
      "Epoch 293/1200\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 23.5822 - val_loss: 37.9895\n",
      "Epoch 294/1200\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 23.4385 - val_loss: 36.2617\n",
      "Epoch 295/1200\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 29.3923 - val_loss: 35.7391\n",
      "Epoch 296/1200\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 16.4111 - val_loss: 33.9302\n",
      "Epoch 297/1200\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 19.4668 - val_loss: 38.6310\n",
      "Epoch 298/1200\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 15.8224 - val_loss: 34.9192\n",
      "Epoch 299/1200\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 15.2788 - val_loss: 34.7875\n",
      "Epoch 300/1200\n",
      "1/1 [==============================] - ETA: 0s - loss: 22.1026\n",
      "Epoch 300: saving model to LSTM+BN5--2022_12_19_14_47_37.hdf5\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 22.1026 - val_loss: 34.4761\n",
      "Epoch 301/1200\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 17.8824 - val_loss: 34.1330\n",
      "Epoch 302/1200\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 26.0242 - val_loss: 31.9238\n",
      "Epoch 303/1200\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 21.9461 - val_loss: 32.4287\n",
      "Epoch 304/1200\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 23.6800 - val_loss: 33.0343\n",
      "Epoch 305/1200\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 38.6433 - val_loss: 32.6950\n",
      "Epoch 306/1200\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 18.2939 - val_loss: 32.4724\n",
      "Epoch 307/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 442ms/step - loss: 17.0908 - val_loss: 30.4058\n",
      "Epoch 308/1200\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 15.3824 - val_loss: 32.6861\n",
      "Epoch 309/1200\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 17.9256 - val_loss: 31.7424\n",
      "Epoch 310/1200\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 19.8163 - val_loss: 31.3995\n",
      "Epoch 311/1200\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 21.1496 - val_loss: 30.1941\n",
      "Epoch 312/1200\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 23.7531 - val_loss: 33.4383\n",
      "Epoch 313/1200\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 25.9757 - val_loss: 29.0469\n",
      "Epoch 314/1200\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 22.0148 - val_loss: 29.3231\n",
      "Epoch 315/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 15.3475 - val_loss: 30.1280\n",
      "Epoch 316/1200\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 15.0383 - val_loss: 29.8713\n",
      "Epoch 317/1200\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 17.3628 - val_loss: 29.9058\n",
      "Epoch 318/1200\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 14.6624 - val_loss: 29.4833\n",
      "Epoch 319/1200\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 19.9372 - val_loss: 29.0410\n",
      "Epoch 320/1200\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 16.8831 - val_loss: 28.8516\n",
      "Epoch 321/1200\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 20.8051 - val_loss: 28.6959\n",
      "Epoch 322/1200\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 18.0915 - val_loss: 28.7613\n",
      "Epoch 323/1200\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 18.4909 - val_loss: 27.7178\n",
      "Epoch 324/1200\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 16.7873 - val_loss: 29.8102\n",
      "Epoch 325/1200\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 16.4743 - val_loss: 27.6630\n",
      "Epoch 326/1200\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 14.2291 - val_loss: 25.9926\n",
      "Epoch 327/1200\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 21.2143 - val_loss: 26.6561\n",
      "Epoch 328/1200\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 18.9289 - val_loss: 25.5689\n",
      "Epoch 329/1200\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 17.3966 - val_loss: 28.3213\n",
      "Epoch 330/1200\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 15.4993 - val_loss: 26.4989\n",
      "Epoch 331/1200\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 16.3662 - val_loss: 26.1136\n",
      "Epoch 332/1200\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 20.1231 - val_loss: 27.4136\n",
      "Epoch 333/1200\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 17.4317 - val_loss: 25.5986\n",
      "Epoch 334/1200\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 13.5739 - val_loss: 25.2954\n",
      "Epoch 335/1200\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 13.4197 - val_loss: 25.3830\n",
      "Epoch 336/1200\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 19.1099 - val_loss: 27.0440\n",
      "Epoch 337/1200\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 15.9573 - val_loss: 23.3109\n",
      "Epoch 338/1200\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 21.4268 - val_loss: 25.9057\n",
      "Epoch 339/1200\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 19.0358 - val_loss: 23.0805\n",
      "Epoch 340/1200\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 19.7317 - val_loss: 24.1427\n",
      "Epoch 341/1200\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 15.4215 - val_loss: 23.9355\n",
      "Epoch 342/1200\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 16.0215 - val_loss: 23.0462\n",
      "Epoch 343/1200\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 13.4984 - val_loss: 24.1601\n",
      "Epoch 344/1200\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 13.4141 - val_loss: 23.2918\n",
      "Epoch 345/1200\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 15.8718 - val_loss: 23.0960\n",
      "Epoch 346/1200\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 15.2728 - val_loss: 21.3487\n",
      "Epoch 347/1200\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 18.3903 - val_loss: 22.7600\n",
      "Epoch 348/1200\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 29.8229 - val_loss: 20.8545\n",
      "Epoch 349/1200\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 15.8970 - val_loss: 22.4174\n",
      "Epoch 350/1200\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 17.7379 - val_loss: 22.1803\n",
      "Epoch 351/1200\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 15.4525 - val_loss: 20.4564\n",
      "Epoch 352/1200\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 16.4554 - val_loss: 22.3199\n",
      "Epoch 353/1200\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 14.9750 - val_loss: 21.8268\n",
      "Epoch 354/1200\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 13.2605 - val_loss: 21.1188\n",
      "Epoch 355/1200\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 23.2761 - val_loss: 21.1921\n",
      "Epoch 356/1200\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 16.9657 - val_loss: 22.2655\n",
      "Epoch 357/1200\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 22.3832 - val_loss: 20.0193\n",
      "Epoch 358/1200\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 47.2730 - val_loss: 21.7077\n",
      "Epoch 359/1200\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 21.5942 - val_loss: 19.6356\n",
      "Epoch 360/1200\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 16.5362 - val_loss: 20.1621\n",
      "Epoch 361/1200\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 12.3669 - val_loss: 19.9780\n",
      "Epoch 362/1200\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 14.4442 - val_loss: 19.5740\n",
      "Epoch 363/1200\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 14.2513 - val_loss: 18.1707\n",
      "Epoch 364/1200\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 12.5591 - val_loss: 19.4794\n",
      "Epoch 365/1200\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 19.7853 - val_loss: 19.3219\n",
      "Epoch 366/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 18.4280 - val_loss: 19.1259\n",
      "Epoch 367/1200\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 16.4655 - val_loss: 17.0970\n",
      "Epoch 368/1200\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 17.4141 - val_loss: 19.5793\n",
      "Epoch 369/1200\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 15.0879 - val_loss: 19.3353\n",
      "Epoch 370/1200\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 12.4218 - val_loss: 18.4264\n",
      "Epoch 371/1200\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 14.3072 - val_loss: 18.4043\n",
      "Epoch 372/1200\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 14.5775 - val_loss: 17.9477\n",
      "Epoch 373/1200\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 23.2318 - val_loss: 17.3958\n",
      "Epoch 374/1200\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 16.5688 - val_loss: 17.9386\n",
      "Epoch 375/1200\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 57.7910 - val_loss: 17.6824\n",
      "Epoch 376/1200\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 24.5372 - val_loss: 17.5800\n",
      "Epoch 377/1200\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 14.8749 - val_loss: 17.5951\n",
      "Epoch 378/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 14.4090 - val_loss: 16.4861\n",
      "Epoch 379/1200\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 14.1034 - val_loss: 17.2175\n",
      "Epoch 380/1200\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 11.5531 - val_loss: 17.0068\n",
      "Epoch 381/1200\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 16.7981 - val_loss: 16.4084\n",
      "Epoch 382/1200\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 14.4362 - val_loss: 17.9967\n",
      "Epoch 383/1200\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 31.4511 - val_loss: 16.0991\n",
      "Epoch 384/1200\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 19.9811 - val_loss: 16.8073\n",
      "Epoch 385/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 15.8554 - val_loss: 16.3052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/1200\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 17.0598 - val_loss: 16.2640\n",
      "Epoch 387/1200\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 15.8255 - val_loss: 15.2319\n",
      "Epoch 388/1200\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 13.4576 - val_loss: 15.9117\n",
      "Epoch 389/1200\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 13.6311 - val_loss: 15.7920\n",
      "Epoch 390/1200\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 20.8695 - val_loss: 15.6450\n",
      "Epoch 391/1200\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 14.6871 - val_loss: 15.4751\n",
      "Epoch 392/1200\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 38.6169 - val_loss: 15.7930\n",
      "Epoch 393/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 28.0999 - val_loss: 15.1423\n",
      "Epoch 394/1200\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 18.8734 - val_loss: 15.2602\n",
      "Epoch 395/1200\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 17.7580 - val_loss: 15.1629\n",
      "Epoch 396/1200\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 13.1441 - val_loss: 13.9843\n",
      "Epoch 397/1200\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 11.7319 - val_loss: 14.7812\n",
      "Epoch 398/1200\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 13.2711 - val_loss: 14.8868\n",
      "Epoch 399/1200\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 14.5049 - val_loss: 14.6289\n",
      "Epoch 400/1200\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.9806\n",
      "Epoch 400: saving model to LSTM+BN5--2022_12_19_14_47_37.hdf5\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 13.9806 - val_loss: 14.5152\n",
      "Epoch 401/1200\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 14.5351 - val_loss: 14.3155\n",
      "Epoch 402/1200\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 18.2751 - val_loss: 15.4221\n",
      "Epoch 403/1200\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 13.8141 - val_loss: 13.2415\n",
      "Epoch 404/1200\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 11.1817 - val_loss: 14.0976\n",
      "Epoch 405/1200\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 14.4509 - val_loss: 13.9601\n",
      "Epoch 406/1200\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 12.9442 - val_loss: 13.8436\n",
      "Epoch 407/1200\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 12.8082 - val_loss: 11.7378\n",
      "Epoch 408/1200\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 13.7896 - val_loss: 14.4529\n",
      "Epoch 409/1200\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 16.6640 - val_loss: 12.5778\n",
      "Epoch 410/1200\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 15.0349 - val_loss: 13.4641\n",
      "Epoch 411/1200\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 26.5925 - val_loss: 13.3829\n",
      "Epoch 412/1200\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 17.8408 - val_loss: 13.0730\n",
      "Epoch 413/1200\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 19.2169 - val_loss: 13.0728\n",
      "Epoch 414/1200\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 15.7994 - val_loss: 12.9878\n",
      "Epoch 415/1200\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 11.0843 - val_loss: 13.0189\n",
      "Epoch 416/1200\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 11.0945 - val_loss: 12.9044\n",
      "Epoch 417/1200\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 12.2377 - val_loss: 12.6849\n",
      "Epoch 418/1200\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 13.5082 - val_loss: 12.7415\n",
      "Epoch 419/1200\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 43.6740 - val_loss: 12.7261\n",
      "Epoch 420/1200\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 14.3074 - val_loss: 12.5819\n",
      "Epoch 421/1200\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 16.3545 - val_loss: 12.5254\n",
      "Epoch 422/1200\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 14.1251 - val_loss: 12.3506\n",
      "Epoch 423/1200\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 10.8535 - val_loss: 12.2860\n",
      "Epoch 424/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 12.9441 - val_loss: 11.1394\n",
      "Epoch 425/1200\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 10.6039 - val_loss: 12.0863\n",
      "Epoch 426/1200\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 11.6197 - val_loss: 11.9921\n",
      "Epoch 427/1200\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 27.1279 - val_loss: 12.4060\n",
      "Epoch 428/1200\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 13.8600 - val_loss: 10.6097\n",
      "Epoch 429/1200\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 32.8713 - val_loss: 12.6616\n",
      "Epoch 430/1200\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 61.6998 - val_loss: 11.7891\n",
      "Epoch 431/1200\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 17.0962 - val_loss: 11.8827\n",
      "Epoch 432/1200\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 14.5116 - val_loss: 12.3727\n",
      "Epoch 433/1200\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 10.2333 - val_loss: 10.5011\n",
      "Epoch 434/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 10.1313 - val_loss: 12.6931\n",
      "Epoch 435/1200\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 13.4449 - val_loss: 11.3783\n",
      "Epoch 436/1200\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 13.4437 - val_loss: 12.3855\n",
      "Epoch 437/1200\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 13.1161 - val_loss: 11.2496\n",
      "Epoch 438/1200\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 12.0362 - val_loss: 11.9932\n",
      "Epoch 439/1200\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 12.2852 - val_loss: 11.0412\n",
      "Epoch 440/1200\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 13.2538 - val_loss: 10.9805\n",
      "Epoch 441/1200\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 11.8162 - val_loss: 10.2741\n",
      "Epoch 442/1200\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 10.1444 - val_loss: 10.0493\n",
      "Epoch 443/1200\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 9.8016 - val_loss: 11.4215\n",
      "Epoch 444/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 14.1317 - val_loss: 10.6976\n",
      "Epoch 445/1200\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 11.3831 - val_loss: 10.5997\n",
      "Epoch 446/1200\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 13.8663 - val_loss: 11.3630\n",
      "Epoch 447/1200\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 14.3862 - val_loss: 10.4949\n",
      "Epoch 448/1200\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 12.7038 - val_loss: 10.8541\n",
      "Epoch 449/1200\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 17.9712 - val_loss: 9.7479\n",
      "Epoch 450/1200\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 10.0372 - val_loss: 10.2646\n",
      "Epoch 451/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 9.8112 - val_loss: 11.2981\n",
      "Epoch 452/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 9.7244 - val_loss: 9.7351\n",
      "Epoch 453/1200\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 25.9218 - val_loss: 11.2418\n",
      "Epoch 454/1200\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 11.4385 - val_loss: 9.4614\n",
      "Epoch 455/1200\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 11.3802 - val_loss: 9.9445\n",
      "Epoch 456/1200\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 14.6932 - val_loss: 10.0090\n",
      "Epoch 457/1200\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 23.0074 - val_loss: 10.1553\n",
      "Epoch 458/1200\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 12.3820 - val_loss: 9.6694\n",
      "Epoch 459/1200\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 12.2862 - val_loss: 9.1770\n",
      "Epoch 460/1200\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 12.0955 - val_loss: 9.6260\n",
      "Epoch 461/1200\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 9.5039 - val_loss: 10.6795\n",
      "Epoch 462/1200\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 12.5548 - val_loss: 8.8466\n",
      "Epoch 463/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 428ms/step - loss: 9.6367 - val_loss: 10.5815\n",
      "Epoch 464/1200\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 9.6514 - val_loss: 10.0705\n",
      "Epoch 465/1200\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 13.1970 - val_loss: 9.3462\n",
      "Epoch 466/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 11.0207 - val_loss: 9.9158\n",
      "Epoch 467/1200\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 11.7077 - val_loss: 9.1755\n",
      "Epoch 468/1200\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 10.5063 - val_loss: 9.8097\n",
      "Epoch 469/1200\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 9.6536 - val_loss: 8.0077\n",
      "Epoch 470/1200\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 9.5649 - val_loss: 9.0729\n",
      "Epoch 471/1200\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 13.7558 - val_loss: 8.9089\n",
      "Epoch 472/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 28.4130 - val_loss: 7.6675\n",
      "Epoch 473/1200\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 29.1468 - val_loss: 9.2213\n",
      "Epoch 474/1200\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 11.8293 - val_loss: 8.6859\n",
      "Epoch 475/1200\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 14.4735 - val_loss: 8.8872\n",
      "Epoch 476/1200\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 12.6234 - val_loss: 8.0363\n",
      "Epoch 477/1200\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 12.0470 - val_loss: 8.7699\n",
      "Epoch 478/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 9.0499 - val_loss: 8.5805\n",
      "Epoch 479/1200\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 8.9311 - val_loss: 8.6509\n",
      "Epoch 480/1200\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 16.0318 - val_loss: 8.6200\n",
      "Epoch 481/1200\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 11.0692 - val_loss: 9.6580\n",
      "Epoch 482/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 15.4189 - val_loss: 6.6493\n",
      "Epoch 483/1200\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 11.5908 - val_loss: 8.4925\n",
      "Epoch 484/1200\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 38.1894 - val_loss: 8.8143\n",
      "Epoch 485/1200\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 11.8222 - val_loss: 8.3820\n",
      "Epoch 486/1200\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 15.2873 - val_loss: 7.9500\n",
      "Epoch 487/1200\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 9.0365 - val_loss: 9.5343\n",
      "Epoch 488/1200\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 8.8285 - val_loss: 8.2436\n",
      "Epoch 489/1200\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 10.2342 - val_loss: 8.5745\n",
      "Epoch 490/1200\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 17.8494 - val_loss: 8.1772\n",
      "Epoch 491/1200\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 11.4737 - val_loss: 7.8684\n",
      "Epoch 492/1200\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 27.3185 - val_loss: 8.6219\n",
      "Epoch 493/1200\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 36.2487 - val_loss: 9.2497\n",
      "Epoch 494/1200\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 37.2645 - val_loss: 7.0161\n",
      "Epoch 495/1200\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 25.6389 - val_loss: 8.0955\n",
      "Epoch 496/1200\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 8.7815 - val_loss: 6.6638\n",
      "Epoch 497/1200\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 11.7044 - val_loss: 9.3738\n",
      "Epoch 498/1200\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 10.2579 - val_loss: 7.5765\n",
      "Epoch 499/1200\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 16.6371 - val_loss: 9.0502\n",
      "Epoch 500/1200\n",
      "1/1 [==============================] - ETA: 0s - loss: 26.8369\n",
      "Epoch 500: saving model to LSTM+BN5--2022_12_19_14_47_37.hdf5\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 26.8369 - val_loss: 7.9529\n",
      "Epoch 501/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 19.3968 - val_loss: 6.5720\n",
      "Epoch 502/1200\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 19.0342 - val_loss: 8.9789\n",
      "Epoch 503/1200\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 10.9883 - val_loss: 7.1156\n",
      "Epoch 504/1200\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 10.7913 - val_loss: 6.6744\n",
      "Epoch 505/1200\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 10.4425 - val_loss: 7.7627\n",
      "Epoch 506/1200\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 10.3213 - val_loss: 7.0588\n",
      "Epoch 507/1200\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 10.1736 - val_loss: 7.6650\n",
      "Epoch 508/1200\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 10.7749 - val_loss: 8.1923\n",
      "Epoch 509/1200\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 20.5072 - val_loss: 7.1231\n",
      "Epoch 510/1200\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 11.6742 - val_loss: 7.5687\n",
      "Epoch 511/1200\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 26.3986 - val_loss: 7.5385\n",
      "Epoch 512/1200\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 16.2815 - val_loss: 7.9505\n",
      "Epoch 513/1200\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 17.7249 - val_loss: 6.3809\n",
      "Epoch 514/1200\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 8.4485 - val_loss: 8.1396\n",
      "Epoch 515/1200\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 10.1901 - val_loss: 7.4341\n",
      "Epoch 516/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 8.8144 - val_loss: 6.6574\n",
      "Epoch 517/1200\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 16.8668 - val_loss: 8.0593\n",
      "Epoch 518/1200\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 12.7305 - val_loss: 6.7571\n",
      "Epoch 519/1200\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 14.9778 - val_loss: 7.2884\n",
      "Epoch 520/1200\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 10.0177 - val_loss: 7.2416\n",
      "Epoch 521/1200\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 8.8557 - val_loss: 6.9394\n",
      "Epoch 522/1200\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 10.0111 - val_loss: 8.7265\n",
      "Epoch 523/1200\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 8.2730 - val_loss: 6.4290\n",
      "Epoch 524/1200\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 9.8644 - val_loss: 7.1053\n",
      "Epoch 525/1200\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 8.3869 - val_loss: 7.0595\n",
      "Epoch 526/1200\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 8.1094 - val_loss: 7.8806\n",
      "Epoch 527/1200\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 14.6600 - val_loss: 5.1695\n",
      "Epoch 528/1200\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 15.3523 - val_loss: 7.2561\n",
      "Epoch 529/1200\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 17.8195 - val_loss: 7.3937\n",
      "Epoch 530/1200\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 12.6941 - val_loss: 6.9330\n",
      "Epoch 531/1200\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 8.2595 - val_loss: 7.0692\n",
      "Epoch 532/1200\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 7.9583 - val_loss: 7.5584\n",
      "Epoch 533/1200\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 9.7278 - val_loss: 6.9547\n",
      "Epoch 534/1200\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 10.7953 - val_loss: 5.3869\n",
      "Epoch 535/1200\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 17.9809 - val_loss: 6.7915\n",
      "Epoch 536/1200\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 10.0241 - val_loss: 6.5985\n",
      "Epoch 537/1200\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 12.9550 - val_loss: 6.1932\n",
      "Epoch 538/1200\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 14.3216 - val_loss: 7.7961\n",
      "Epoch 539/1200\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 14.0902 - val_loss: 6.2745\n",
      "Epoch 540/1200\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 15.4681 - val_loss: 6.6534\n",
      "Epoch 541/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 390ms/step - loss: 10.0724 - val_loss: 7.0240\n",
      "Epoch 542/1200\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 9.9484 - val_loss: 6.1264\n",
      "Epoch 543/1200\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 15.1105 - val_loss: 6.7705\n",
      "Epoch 544/1200\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 10.5595 - val_loss: 7.1045\n",
      "Epoch 545/1200\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 15.8160 - val_loss: 6.5387\n",
      "Epoch 546/1200\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 12.7761 - val_loss: 6.8320\n",
      "Epoch 547/1200\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 10.8279 - val_loss: 7.6031\n",
      "Epoch 548/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 13.9035 - val_loss: 5.1886\n",
      "Epoch 549/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 12.1707 - val_loss: 6.4555\n",
      "Epoch 550/1200\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 7.9801 - val_loss: 6.4279\n",
      "Epoch 551/1200\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 9.6811 - val_loss: 5.6984\n",
      "Epoch 552/1200\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 9.4252 - val_loss: 6.1879\n",
      "Epoch 553/1200\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 11.6857 - val_loss: 7.5854\n",
      "Epoch 554/1200\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 11.3707 - val_loss: 4.8923\n",
      "Epoch 555/1200\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 17.5912 - val_loss: 6.3334\n",
      "Epoch 556/1200\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 13.1070 - val_loss: 5.5957\n",
      "Epoch 557/1200\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 14.5647 - val_loss: 4.9943\n",
      "Epoch 558/1200\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 11.2390 - val_loss: 5.5667\n",
      "Epoch 559/1200\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 7.7003 - val_loss: 5.9354\n",
      "Epoch 560/1200\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 7.6226 - val_loss: 6.2038\n",
      "Epoch 561/1200\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 11.7294 - val_loss: 5.2920\n",
      "Epoch 562/1200\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 19.7629 - val_loss: 7.7793\n",
      "Epoch 563/1200\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 19.9161 - val_loss: 5.8114\n",
      "Epoch 564/1200\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 17.2959 - val_loss: 6.1770\n",
      "Epoch 565/1200\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 14.9278 - val_loss: 6.1537\n",
      "Epoch 566/1200\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 21.2316 - val_loss: 6.3337\n",
      "Epoch 567/1200\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 7.5057 - val_loss: 6.6535\n",
      "Epoch 568/1200\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 7.9763 - val_loss: 5.6141\n",
      "Epoch 569/1200\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 7.4577 - val_loss: 5.8746\n",
      "Epoch 570/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 9.4405 - val_loss: 6.0479\n",
      "Epoch 571/1200\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 9.1655 - val_loss: 6.3686\n",
      "Epoch 572/1200\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 13.8894 - val_loss: 6.4564\n",
      "Epoch 573/1200\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 9.3615 - val_loss: 6.7134\n",
      "Epoch 574/1200\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 19.7595 - val_loss: 6.2782\n",
      "Epoch 575/1200\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 9.0369 - val_loss: 5.9267\n",
      "Epoch 576/1200\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 7.2334 - val_loss: 6.0532\n",
      "Epoch 577/1200\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 9.2485 - val_loss: 4.7931\n",
      "Epoch 578/1200\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 8.7506 - val_loss: 6.3060\n",
      "Epoch 579/1200\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 10.1563 - val_loss: 5.9899\n",
      "Epoch 580/1200\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 17.4531 - val_loss: 5.8293\n",
      "Epoch 581/1200\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 9.0181 - val_loss: 5.7980\n",
      "Epoch 582/1200\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 10.1028 - val_loss: 5.6325\n",
      "Epoch 583/1200\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 10.7862 - val_loss: 4.9863\n",
      "Epoch 584/1200\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 10.3508 - val_loss: 5.8796\n",
      "Epoch 585/1200\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 8.2286 - val_loss: 5.7085\n",
      "Epoch 586/1200\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 7.1423 - val_loss: 4.6167\n",
      "Epoch 587/1200\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 9.5816 - val_loss: 7.1877\n",
      "Epoch 588/1200\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 14.3953 - val_loss: 5.6618\n",
      "Epoch 589/1200\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 9.7472 - val_loss: 5.6448\n",
      "Epoch 590/1200\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 10.6531 - val_loss: 5.6309\n",
      "Epoch 591/1200\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 18.0335 - val_loss: 5.3056\n",
      "Epoch 592/1200\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 8.4375 - val_loss: 5.7526\n",
      "Epoch 593/1200\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 13.7722 - val_loss: 5.5842\n",
      "Epoch 594/1200\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 12.4090 - val_loss: 6.6387\n",
      "Epoch 595/1200\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 6.8493 - val_loss: 5.5501\n",
      "Epoch 596/1200\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 7.4077 - val_loss: 5.3755\n",
      "Epoch 597/1200\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 10.1385 - val_loss: 5.5059\n",
      "Epoch 598/1200\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 13.4650 - val_loss: 6.1465\n",
      "Epoch 599/1200\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 13.0558 - val_loss: 4.8701\n",
      "Epoch 600/1200\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.2434\n",
      "Epoch 600: saving model to LSTM+BN5--2022_12_19_14_47_37.hdf5\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 9.2434 - val_loss: 5.4651\n",
      "Epoch 601/1200\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 21.5485 - val_loss: 5.4694\n",
      "Epoch 602/1200\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 9.7604 - val_loss: 5.1514\n",
      "Epoch 603/1200\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 8.4825 - val_loss: 6.0488\n",
      "Epoch 604/1200\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 7.3095 - val_loss: 4.6325\n",
      "Epoch 605/1200\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 6.6258 - val_loss: 5.3753\n",
      "Epoch 606/1200\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 8.1751 - val_loss: 6.7417\n",
      "Epoch 607/1200\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 10.6429 - val_loss: 5.3396\n",
      "Epoch 608/1200\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 7.3870 - val_loss: 4.6621\n",
      "Epoch 609/1200\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 9.8245 - val_loss: 6.0737\n",
      "Epoch 610/1200\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 19.7129 - val_loss: 5.2996\n",
      "Epoch 611/1200\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 10.0127 - val_loss: 5.7218\n",
      "Epoch 612/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 7.7110 - val_loss: 6.4901\n",
      "Epoch 613/1200\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 6.7315 - val_loss: 5.8186\n",
      "Epoch 614/1200\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 7.9688 - val_loss: 4.9162\n",
      "Epoch 615/1200\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 11.9977 - val_loss: 5.2085\n",
      "Epoch 616/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 8.9232 - val_loss: 5.1929\n",
      "Epoch 617/1200\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 10.8473 - val_loss: 3.8405\n",
      "Epoch 618/1200\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 24.5585 - val_loss: 6.4046\n",
      "Epoch 619/1200\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 50.4402 - val_loss: 4.8950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 620/1200\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 10.2777 - val_loss: 5.1882\n",
      "Epoch 621/1200\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 9.0526 - val_loss: 5.6164\n",
      "Epoch 622/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 6.5497 - val_loss: 4.1190\n",
      "Epoch 623/1200\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 8.0338 - val_loss: 4.6932\n",
      "Epoch 624/1200\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 6.4922 - val_loss: 4.9728\n",
      "Epoch 625/1200\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 10.9533 - val_loss: 5.1116\n",
      "Epoch 626/1200\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 9.5355 - val_loss: 5.8599\n",
      "Epoch 627/1200\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 8.9238 - val_loss: 4.5139\n",
      "Epoch 628/1200\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 8.6139 - val_loss: 5.5180\n",
      "Epoch 629/1200\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 19.8943 - val_loss: 4.7578\n",
      "Epoch 630/1200\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 8.1940 - val_loss: 5.0509\n",
      "Epoch 631/1200\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 6.3853 - val_loss: 5.1441\n",
      "Epoch 632/1200\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 6.4667 - val_loss: 5.4372\n",
      "Epoch 633/1200\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 9.5930 - val_loss: 5.2882\n",
      "Epoch 634/1200\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 6.7462 - val_loss: 3.6633\n",
      "Epoch 635/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 7.9193 - val_loss: 4.9612\n",
      "Epoch 636/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 16.7218 - val_loss: 4.8345\n",
      "Epoch 637/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 17.7263 - val_loss: 6.4039\n",
      "Epoch 638/1200\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 11.1385 - val_loss: 4.8267\n",
      "Epoch 639/1200\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 6.2678 - val_loss: 4.6558\n",
      "Epoch 640/1200\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 7.7055 - val_loss: 4.9215\n",
      "Epoch 641/1200\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 8.0173 - val_loss: 4.0178\n",
      "Epoch 642/1200\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 13.5727 - val_loss: 5.1937\n",
      "Epoch 643/1200\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 8.8592 - val_loss: 5.4296\n",
      "Epoch 644/1200\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 11.9186 - val_loss: 4.8895\n",
      "Epoch 645/1200\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 11.2499 - val_loss: 4.8819\n",
      "Epoch 646/1200\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 7.5417 - val_loss: 3.5528\n",
      "Epoch 647/1200\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 13.2627 - val_loss: 5.3925\n",
      "Epoch 648/1200\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 10.2919 - val_loss: 5.1311\n",
      "Epoch 649/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 6.6676 - val_loss: 4.5150\n",
      "Epoch 650/1200\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 6.1189 - val_loss: 4.7962\n",
      "Epoch 651/1200\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 7.3850 - val_loss: 5.0836\n",
      "Epoch 652/1200\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 9.4190 - val_loss: 5.9139\n",
      "Epoch 653/1200\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 22.1021 - val_loss: 4.3407\n",
      "Epoch 654/1200\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 10.0305 - val_loss: 4.5171\n",
      "Epoch 655/1200\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 19.8031 - val_loss: 4.7658\n",
      "Epoch 656/1200\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 17.3648 - val_loss: 4.2364\n",
      "Epoch 657/1200\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 10.1300 - val_loss: 4.8645\n",
      "Epoch 658/1200\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 7.6788 - val_loss: 4.5083\n",
      "Epoch 659/1200\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 6.1615 - val_loss: 5.4926\n",
      "Epoch 660/1200\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 8.3753 - val_loss: 4.7113\n",
      "Epoch 661/1200\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 8.6137 - val_loss: 4.6877\n",
      "Epoch 662/1200\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 15.0750 - val_loss: 4.3064\n",
      "Epoch 663/1200\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 12.7817 - val_loss: 3.9489\n",
      "Epoch 664/1200\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 5.8908 - val_loss: 4.6784\n",
      "Epoch 665/1200\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 11.1116 - val_loss: 4.6615\n",
      "Epoch 666/1200\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 5.8213 - val_loss: 4.9274\n",
      "Epoch 667/1200\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 6.4563 - val_loss: 5.5098\n",
      "Epoch 668/1200\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 6.3923 - val_loss: 3.5722\n",
      "Epoch 669/1200\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 8.9546 - val_loss: 5.3629\n",
      "Epoch 670/1200\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 11.0348 - val_loss: 4.5896\n",
      "Epoch 671/1200\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 8.6350 - val_loss: 3.6764\n",
      "Epoch 672/1200\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 7.3976 - val_loss: 4.1696\n",
      "Epoch 673/1200\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 12.8891 - val_loss: 3.6580\n",
      "Epoch 674/1200\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 9.5091 - val_loss: 4.7779\n",
      "Epoch 675/1200\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 10.2246 - val_loss: 4.5277\n",
      "Epoch 676/1200\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 6.2550 - val_loss: 3.7485\n",
      "Epoch 677/1200\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 5.8210 - val_loss: 4.2779\n",
      "Epoch 678/1200\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 6.9346 - val_loss: 5.9669\n",
      "Epoch 679/1200\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 6.8797 - val_loss: 4.4816\n",
      "Epoch 680/1200\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 11.3216 - val_loss: 4.4913\n",
      "Epoch 681/1200\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 34.5152 - val_loss: 4.5933\n",
      "Epoch 682/1200\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 8.2691 - val_loss: 3.6803\n",
      "Epoch 683/1200\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 6.7064 - val_loss: 4.3548\n",
      "Epoch 684/1200\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 6.3068 - val_loss: 3.2224\n",
      "Epoch 685/1200\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 5.7601 - val_loss: 4.4465\n",
      "Epoch 686/1200\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 5.7083 - val_loss: 3.4790\n",
      "Epoch 687/1200\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 7.0154 - val_loss: 4.4196\n",
      "Epoch 688/1200\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 7.7323 - val_loss: 4.1331\n",
      "Epoch 689/1200\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 7.3984 - val_loss: 3.4383\n",
      "Epoch 690/1200\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 8.8125 - val_loss: 4.3768\n",
      "Epoch 691/1200\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 20.3561 - val_loss: 5.2491\n",
      "Epoch 692/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 7.1605 - val_loss: 3.2441\n",
      "Epoch 693/1200\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 6.3118 - val_loss: 5.0990\n",
      "Epoch 694/1200\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 5.9217 - val_loss: 3.4044\n",
      "Epoch 695/1200\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 5.5641 - val_loss: 4.3452\n",
      "Epoch 696/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 6.1003 - val_loss: 5.5418\n",
      "Epoch 697/1200\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 8.6997 - val_loss: 3.5764\n",
      "Epoch 698/1200\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 9.1839 - val_loss: 3.9549\n",
      "Epoch 699/1200\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 6.1591 - val_loss: 4.2936\n",
      "Epoch 700/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 9.8251\n",
      "Epoch 700: saving model to LSTM+BN5--2022_12_19_14_47_37.hdf5\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 9.8251 - val_loss: 4.2873\n",
      "Epoch 701/1200\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 5.9999 - val_loss: 4.4712\n",
      "Epoch 702/1200\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 5.4660 - val_loss: 4.2562\n",
      "Epoch 703/1200\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 6.5512 - val_loss: 3.8979\n",
      "Epoch 704/1200\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 5.7374 - val_loss: 3.3862\n",
      "Epoch 705/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 8.3960 - val_loss: 4.2318\n",
      "Epoch 706/1200\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 8.7264 - val_loss: 4.3419\n",
      "Epoch 707/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 8.5803 - val_loss: 4.9523\n",
      "Epoch 708/1200\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 7.6514 - val_loss: 3.8542\n",
      "Epoch 709/1200\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 7.3910 - val_loss: 4.0588\n",
      "Epoch 710/1200\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 7.9714 - val_loss: 4.1831\n",
      "Epoch 711/1200\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 7.3351 - val_loss: 4.1713\n",
      "Epoch 712/1200\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 5.3074 - val_loss: 3.0365\n",
      "Epoch 713/1200\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 5.1848 - val_loss: 3.2068\n",
      "Epoch 714/1200\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 7.7306 - val_loss: 5.0686\n",
      "Epoch 715/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 20.0298 - val_loss: 4.1265\n",
      "Epoch 716/1200\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 8.5940 - val_loss: 4.1211\n",
      "Epoch 717/1200\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 12.5260 - val_loss: 5.4227\n",
      "Epoch 718/1200\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 9.0655 - val_loss: 2.8155\n",
      "Epoch 719/1200\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 6.0248 - val_loss: 4.4146\n",
      "Epoch 720/1200\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 7.0278 - val_loss: 4.0672\n",
      "Epoch 721/1200\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 5.2199 - val_loss: 4.9063\n",
      "Epoch 722/1200\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 5.1710 - val_loss: 2.9949\n",
      "Epoch 723/1200\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 5.0510 - val_loss: 3.7864\n",
      "Epoch 724/1200\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 10.7099 - val_loss: 4.2326\n",
      "Epoch 725/1200\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 10.2412 - val_loss: 4.0391\n",
      "Epoch 726/1200\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 19.1127 - val_loss: 4.2228\n",
      "Epoch 727/1200\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 7.5291 - val_loss: 3.1965\n",
      "Epoch 728/1200\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 8.9219 - val_loss: 4.5844\n",
      "Epoch 729/1200\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 8.6022 - val_loss: 3.8237\n",
      "Epoch 730/1200\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 5.0058 - val_loss: 3.9862\n",
      "Epoch 731/1200\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 5.1442 - val_loss: 5.1258\n",
      "Epoch 732/1200\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 5.0173 - val_loss: 3.6341\n",
      "Epoch 733/1200\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 7.2514 - val_loss: 3.9568\n",
      "Epoch 734/1200\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 8.7700 - val_loss: 3.9547\n",
      "Epoch 735/1200\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 25.2017 - val_loss: 3.9453\n",
      "Epoch 736/1200\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 7.2075 - val_loss: 4.0346\n",
      "Epoch 737/1200\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 7.4101 - val_loss: 4.4000\n",
      "Epoch 738/1200\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 5.0768 - val_loss: 3.0891\n",
      "Epoch 739/1200\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 5.3275 - val_loss: 3.9026\n",
      "Epoch 740/1200\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 7.0308 - val_loss: 3.8932\n",
      "Epoch 741/1200\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 8.0952 - val_loss: 3.7940\n",
      "Epoch 742/1200\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 7.4451 - val_loss: 4.2934\n",
      "Epoch 743/1200\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 11.3778 - val_loss: 4.9422\n",
      "Epoch 744/1200\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 9.9910 - val_loss: 3.6528\n",
      "Epoch 745/1200\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 6.7920 - val_loss: 3.8635\n",
      "Epoch 746/1200\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 9.7285 - val_loss: 2.9654\n",
      "Epoch 747/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 8.3506 - val_loss: 3.9512\n",
      "Epoch 748/1200\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 5.9816 - val_loss: 4.5748\n",
      "Epoch 749/1200\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 5.8862 - val_loss: 3.1299\n",
      "Epoch 750/1200\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 6.9285 - val_loss: 3.8324\n",
      "Epoch 751/1200\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 7.9228 - val_loss: 3.8200\n",
      "Epoch 752/1200\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 10.4703 - val_loss: 3.6747\n",
      "Epoch 753/1200\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 5.8081 - val_loss: 4.5232\n",
      "Epoch 754/1200\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 12.9703 - val_loss: 3.8304\n",
      "Epoch 755/1200\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 6.9888 - val_loss: 3.8223\n",
      "Epoch 756/1200\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 6.4660 - val_loss: 4.2350\n",
      "Epoch 757/1200\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 5.7045 - val_loss: 3.8027\n",
      "Epoch 758/1200\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 6.5295 - val_loss: 4.4956\n",
      "Epoch 759/1200\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 4.6944 - val_loss: 3.7719\n",
      "Epoch 760/1200\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 19.1462 - val_loss: 3.7922\n",
      "Epoch 761/1200\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 20.2759 - val_loss: 4.6543\n",
      "Epoch 762/1200\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 9.4276 - val_loss: 3.6728\n",
      "Epoch 763/1200\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 15.5267 - val_loss: 3.6213\n",
      "Epoch 764/1200\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 12.1231 - val_loss: 4.0497\n",
      "Epoch 765/1200\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 6.4228 - val_loss: 3.7868\n",
      "Epoch 766/1200\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 4.9027 - val_loss: 3.4491\n",
      "Epoch 767/1200\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 4.7847 - val_loss: 2.8833\n",
      "Epoch 768/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 6.6309 - val_loss: 4.6000\n",
      "Epoch 769/1200\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 11.6922 - val_loss: 3.7627\n",
      "Epoch 770/1200\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 6.9276 - val_loss: 3.7576\n",
      "Epoch 771/1200\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 5.7590 - val_loss: 3.7454\n",
      "Epoch 772/1200\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 6.9066 - val_loss: 2.9371\n",
      "Epoch 773/1200\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 6.5436 - val_loss: 4.9180\n",
      "Epoch 774/1200\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 6.1675 - val_loss: 4.0134\n",
      "Epoch 775/1200\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 4.7596 - val_loss: 3.6838\n",
      "Epoch 776/1200\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 5.0208 - val_loss: 4.4645\n",
      "Epoch 777/1200\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 5.7217 - val_loss: 2.4907\n",
      "Epoch 778/1200\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 11.8267 - val_loss: 4.7475\n",
      "Epoch 779/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 461ms/step - loss: 8.5977 - val_loss: 3.7356\n",
      "Epoch 780/1200\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 14.1925 - val_loss: 3.6374\n",
      "Epoch 781/1200\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 6.0819 - val_loss: 3.7787\n",
      "Epoch 782/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 11.9870 - val_loss: 3.3901\n",
      "Epoch 783/1200\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 10.5196 - val_loss: 3.5443\n",
      "Epoch 784/1200\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 4.6867 - val_loss: 3.7023\n",
      "Epoch 785/1200\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 4.5465 - val_loss: 3.6067\n",
      "Epoch 786/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 6.6076 - val_loss: 3.5994\n",
      "Epoch 787/1200\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 5.0457 - val_loss: 3.2763\n",
      "Epoch 788/1200\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 9.1494 - val_loss: 4.5784\n",
      "Epoch 789/1200\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 6.7275 - val_loss: 3.5695\n",
      "Epoch 790/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 8.4883 - val_loss: 3.5667\n",
      "Epoch 791/1200\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 4.8445 - val_loss: 3.4720\n",
      "Epoch 792/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 4.7563 - val_loss: 4.3198\n",
      "Epoch 793/1200\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 4.5351 - val_loss: 3.2307\n",
      "Epoch 794/1200\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 4.4914 - val_loss: 3.4525\n",
      "Epoch 795/1200\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 14.7257 - val_loss: 3.5086\n",
      "Epoch 796/1200\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 6.3187 - val_loss: 2.4396\n",
      "Epoch 797/1200\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 8.2608 - val_loss: 3.7937\n",
      "Epoch 798/1200\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 27.7080 - val_loss: 3.1245\n",
      "Epoch 799/1200\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 8.1944 - val_loss: 3.6294\n",
      "Epoch 800/1200\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.3286\n",
      "Epoch 800: saving model to LSTM+BN5--2022_12_19_14_47_37.hdf5\n",
      "1/1 [==============================] - 1s 643ms/step - loss: 5.3286 - val_loss: 3.4780\n",
      "Epoch 801/1200\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 5.2247 - val_loss: 3.5412\n",
      "Epoch 802/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 4.4255 - val_loss: 3.3772\n",
      "Epoch 803/1200\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 5.7760 - val_loss: 3.5221\n",
      "Epoch 804/1200\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 6.0106 - val_loss: 3.4404\n",
      "Epoch 805/1200\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 5.7588 - val_loss: 3.4331\n",
      "Epoch 806/1200\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 19.1718 - val_loss: 3.6969\n",
      "Epoch 807/1200\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 15.1878 - val_loss: 3.5243\n",
      "Epoch 808/1200\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 18.0242 - val_loss: 3.0384\n",
      "Epoch 809/1200\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 5.4277 - val_loss: 3.2509\n",
      "Epoch 810/1200\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 6.2048 - val_loss: 3.3701\n",
      "Epoch 811/1200\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 4.3328 - val_loss: 3.6495\n",
      "Epoch 812/1200\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 4.3288 - val_loss: 3.4169\n",
      "Epoch 813/1200\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 6.9924 - val_loss: 2.5406\n",
      "Epoch 814/1200\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 5.8564 - val_loss: 3.3372\n",
      "Epoch 815/1200\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 8.4037 - val_loss: 3.3337\n",
      "Epoch 816/1200\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 41.4789 - val_loss: 3.3512\n",
      "Epoch 817/1200\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 13.5621 - val_loss: 4.0980\n",
      "Epoch 818/1200\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 6.0042 - val_loss: 3.4873\n",
      "Epoch 819/1200\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 7.6820 - val_loss: 2.6029\n",
      "Epoch 820/1200\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 4.2324 - val_loss: 3.3308\n",
      "Epoch 821/1200\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 5.2075 - val_loss: 3.6891\n",
      "Epoch 822/1200\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 4.1160 - val_loss: 3.5947\n",
      "Epoch 823/1200\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 6.4288 - val_loss: 4.0964\n",
      "Epoch 824/1200\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 10.6032 - val_loss: 2.9542\n",
      "Epoch 825/1200\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 11.3831 - val_loss: 3.3043\n",
      "Epoch 826/1200\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 9.7018 - val_loss: 3.0216\n",
      "Epoch 827/1200\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 6.0689 - val_loss: 4.3033\n",
      "Epoch 828/1200\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 4.8824 - val_loss: 3.1504\n",
      "Epoch 829/1200\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 4.1637 - val_loss: 2.9191\n",
      "Epoch 830/1200\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 5.5660 - val_loss: 3.2755\n",
      "Epoch 831/1200\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 5.1239 - val_loss: 3.9116\n",
      "Epoch 832/1200\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 8.2036 - val_loss: 2.4856\n",
      "Epoch 833/1200\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 10.6135 - val_loss: 3.6064\n",
      "Epoch 834/1200\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 9.9915 - val_loss: 3.0296\n",
      "Epoch 835/1200\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 6.2040 - val_loss: 3.2423\n",
      "Epoch 836/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 6.4304 - val_loss: 3.4603\n",
      "Epoch 837/1200\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 6.1643 - val_loss: 2.9394\n",
      "Epoch 838/1200\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 5.5083 - val_loss: 3.2242\n",
      "Epoch 839/1200\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 3.9836 - val_loss: 3.2114\n",
      "Epoch 840/1200\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 4.7393 - val_loss: 3.2046\n",
      "Epoch 841/1200\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 5.8283 - val_loss: 3.9113\n",
      "Epoch 842/1200\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 7.1759 - val_loss: 2.1494\n",
      "Epoch 843/1200\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 6.7378 - val_loss: 3.5389\n",
      "Epoch 844/1200\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 9.4566 - val_loss: 2.8294\n",
      "Epoch 845/1200\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 10.9071 - val_loss: 3.1867\n",
      "Epoch 846/1200\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 5.2846 - val_loss: 3.1782\n",
      "Epoch 847/1200\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 5.4156 - val_loss: 2.8202\n",
      "Epoch 848/1200\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 5.3446 - val_loss: 4.1596\n",
      "Epoch 849/1200\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 8.8049 - val_loss: 3.0924\n",
      "Epoch 850/1200\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 6.8841 - val_loss: 3.1765\n",
      "Epoch 851/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 5.7857 - val_loss: 3.1741\n",
      "Epoch 852/1200\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 6.0351 - val_loss: 2.2343\n",
      "Epoch 853/1200\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 11.0973 - val_loss: 3.8703\n",
      "Epoch 854/1200\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 7.3573 - val_loss: 3.1477\n",
      "Epoch 855/1200\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 9.3168 - val_loss: 3.1559\n",
      "Epoch 856/1200\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 5.1943 - val_loss: 3.2052\n",
      "Epoch 857/1200\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 4.5780 - val_loss: 2.5119\n",
      "Epoch 858/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 397ms/step - loss: 4.6907 - val_loss: 3.1363\n",
      "Epoch 859/1200\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 6.2789 - val_loss: 2.9188\n",
      "Epoch 860/1200\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 7.2531 - val_loss: 3.1321\n",
      "Epoch 861/1200\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 5.8586 - val_loss: 3.1279\n",
      "Epoch 862/1200\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 5.0421 - val_loss: 2.8551\n",
      "Epoch 863/1200\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 7.7185 - val_loss: 3.4826\n",
      "Epoch 864/1200\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 14.5940 - val_loss: 2.7747\n",
      "Epoch 865/1200\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 3.9387 - val_loss: 3.1155\n",
      "Epoch 866/1200\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 3.8628 - val_loss: 4.0796\n",
      "Epoch 867/1200\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 5.1628 - val_loss: 3.1010\n",
      "Epoch 868/1200\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 3.9578 - val_loss: 3.3494\n",
      "Epoch 869/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 4.5268 - val_loss: 3.4233\n",
      "Epoch 870/1200\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 5.6289 - val_loss: 3.0698\n",
      "Epoch 871/1200\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 6.6028 - val_loss: 3.3306\n",
      "Epoch 872/1200\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 4.2969 - val_loss: 3.1400\n",
      "Epoch 873/1200\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 5.7691 - val_loss: 3.2578\n",
      "Epoch 874/1200\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 4.1766 - val_loss: 3.0483\n",
      "Epoch 875/1200\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 4.3830 - val_loss: 3.0404\n",
      "Epoch 876/1200\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 7.5811 - val_loss: 4.0064\n",
      "Epoch 877/1200\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 7.0240 - val_loss: 2.0923\n",
      "Epoch 878/1200\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 7.1907 - val_loss: 2.9880\n",
      "Epoch 879/1200\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 5.4383 - val_loss: 3.2772\n",
      "Epoch 880/1200\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 4.8602 - val_loss: 3.0195\n",
      "Epoch 881/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 4.6506 - val_loss: 2.2825\n",
      "Epoch 882/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 6.2902 - val_loss: 3.0846\n",
      "Epoch 883/1200\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 3.8405 - val_loss: 2.9241\n",
      "Epoch 884/1200\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 4.2536 - val_loss: 2.9908\n",
      "Epoch 885/1200\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 5.2719 - val_loss: 2.9936\n",
      "Epoch 886/1200\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 8.3581 - val_loss: 2.7759\n",
      "Epoch 887/1200\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 4.6295 - val_loss: 2.2635\n",
      "Epoch 888/1200\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 5.7447 - val_loss: 2.2943\n",
      "Epoch 889/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 7.8076 - val_loss: 3.0496\n",
      "Epoch 890/1200\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 4.4347 - val_loss: 2.9643\n",
      "Epoch 891/1200\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 3.7460 - val_loss: 2.7403\n",
      "Epoch 892/1200\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 4.7558 - val_loss: 3.7438\n",
      "Epoch 893/1200\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 4.6940 - val_loss: 3.0601\n",
      "Epoch 894/1200\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 5.0935 - val_loss: 2.2476\n",
      "Epoch 895/1200\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 8.9322 - val_loss: 2.9430\n",
      "Epoch 896/1200\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 8.6910 - val_loss: 3.1736\n",
      "Epoch 897/1200\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 8.8219 - val_loss: 2.8165\n",
      "Epoch 898/1200\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 5.2635 - val_loss: 3.5940\n",
      "Epoch 899/1200\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 15.0229 - val_loss: 2.7309\n",
      "Epoch 900/1200\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.1260\n",
      "Epoch 900: saving model to LSTM+BN5--2022_12_19_14_47_37.hdf5\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 7.1260 - val_loss: 2.9336\n",
      "Epoch 901/1200\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 4.1096 - val_loss: 2.8048\n",
      "Epoch 902/1200\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 3.5316 - val_loss: 3.8087\n",
      "Epoch 903/1200\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 6.8903 - val_loss: 2.0470\n",
      "Epoch 904/1200\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 3.9617 - val_loss: 3.4787\n",
      "Epoch 905/1200\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 4.5961 - val_loss: 2.8919\n",
      "Epoch 906/1200\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 5.9557 - val_loss: 2.1814\n",
      "Epoch 907/1200\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 12.6133 - val_loss: 3.8095\n",
      "Epoch 908/1200\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 4.0148 - val_loss: 2.2850\n",
      "Epoch 909/1200\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 4.2234 - val_loss: 3.5219\n",
      "Epoch 910/1200\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 3.6129 - val_loss: 2.8517\n",
      "Epoch 911/1200\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 3.5765 - val_loss: 2.2625\n",
      "Epoch 912/1200\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 5.6045 - val_loss: 2.8364\n",
      "Epoch 913/1200\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 6.3532 - val_loss: 3.4837\n",
      "Epoch 914/1200\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 5.2491 - val_loss: 2.8267\n",
      "Epoch 915/1200\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 5.3171 - val_loss: 2.8217\n",
      "Epoch 916/1200\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 5.1879 - val_loss: 2.1277\n",
      "Epoch 917/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 7.9234 - val_loss: 2.8203\n",
      "Epoch 918/1200\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 4.2803 - val_loss: 3.5045\n",
      "Epoch 919/1200\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 4.4843 - val_loss: 2.8121\n",
      "Epoch 920/1200\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 3.4509 - val_loss: 2.8032\n",
      "Epoch 921/1200\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 4.4236 - val_loss: 2.7987\n",
      "Epoch 922/1200\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 9.7515 - val_loss: 2.9072\n",
      "Epoch 923/1200\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 20.7631 - val_loss: 3.0349\n",
      "Epoch 924/1200\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 5.7398 - val_loss: 2.6018\n",
      "Epoch 925/1200\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 6.9728 - val_loss: 2.8007\n",
      "Epoch 926/1200\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 15.9861 - val_loss: 3.0289\n",
      "Epoch 927/1200\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 9.3858 - val_loss: 2.7715\n",
      "Epoch 928/1200\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 4.6034 - val_loss: 2.7949\n",
      "Epoch 929/1200\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 3.7528 - val_loss: 2.8721\n",
      "Epoch 930/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 3.7348 - val_loss: 2.7717\n",
      "Epoch 931/1200\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 6.1650 - val_loss: 2.6807\n",
      "Epoch 932/1200\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 5.1063 - val_loss: 3.4975\n",
      "Epoch 933/1200\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 9.7465 - val_loss: 2.2983\n",
      "Epoch 934/1200\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 6.8563 - val_loss: 3.2905\n",
      "Epoch 935/1200\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 5.0544 - val_loss: 2.7258\n",
      "Epoch 936/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 5.2062 - val_loss: 3.3423\n",
      "Epoch 937/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 413ms/step - loss: 3.3091 - val_loss: 2.1982\n",
      "Epoch 938/1200\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 4.1180 - val_loss: 3.2579\n",
      "Epoch 939/1200\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 4.7892 - val_loss: 2.3989\n",
      "Epoch 940/1200\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 4.1988 - val_loss: 2.6903\n",
      "Epoch 941/1200\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 11.1235 - val_loss: 3.3548\n",
      "Epoch 942/1200\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 6.7820 - val_loss: 1.8384\n",
      "Epoch 943/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 15.5618 - val_loss: 3.5274\n",
      "Epoch 944/1200\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 4.8494 - val_loss: 2.4941\n",
      "Epoch 945/1200\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 6.5805 - val_loss: 2.6747\n",
      "Epoch 946/1200\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 4.2701 - val_loss: 2.6710\n",
      "Epoch 947/1200\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 4.4160 - val_loss: 2.8762\n",
      "Epoch 948/1200\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 4.8250 - val_loss: 2.4473\n",
      "Epoch 949/1200\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 4.8388 - val_loss: 2.6537\n",
      "Epoch 950/1200\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 13.6220 - val_loss: 2.6700\n",
      "Epoch 951/1200\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 4.9841 - val_loss: 2.8718\n",
      "Epoch 952/1200\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 3.5549 - val_loss: 3.4925\n",
      "Epoch 953/1200\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 8.8246 - val_loss: 2.6517\n",
      "Epoch 954/1200\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 3.7350 - val_loss: 2.6033\n",
      "Epoch 955/1200\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 3.2934 - val_loss: 2.6301\n",
      "Epoch 956/1200\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 3.5486 - val_loss: 2.0072\n",
      "Epoch 957/1200\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 4.2593 - val_loss: 1.9614\n",
      "Epoch 958/1200\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 5.5402 - val_loss: 2.4099\n",
      "Epoch 959/1200\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 5.2049 - val_loss: 2.6935\n",
      "Epoch 960/1200\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 4.9424 - val_loss: 2.6053\n",
      "Epoch 961/1200\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 4.7676 - val_loss: 3.4254\n",
      "Epoch 962/1200\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 7.9540 - val_loss: 2.6274\n",
      "Epoch 963/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 4.3665 - val_loss: 2.0598\n",
      "Epoch 964/1200\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 4.0930 - val_loss: 3.3985\n",
      "Epoch 965/1200\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 4.1921 - val_loss: 2.5814\n",
      "Epoch 966/1200\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 8.8099 - val_loss: 2.5884\n",
      "Epoch 967/1200\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 3.7167 - val_loss: 2.3319\n",
      "Epoch 968/1200\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 14.9502 - val_loss: 3.4716\n",
      "Epoch 969/1200\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 8.7750 - val_loss: 2.3048\n",
      "Epoch 970/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 7.2745 - val_loss: 2.5811\n",
      "Epoch 971/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 5.1915 - val_loss: 2.6857\n",
      "Epoch 972/1200\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 4.5227 - val_loss: 2.8763\n",
      "Epoch 973/1200\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 4.1187 - val_loss: 2.6778\n",
      "Epoch 974/1200\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 3.0811 - val_loss: 2.4273\n",
      "Epoch 975/1200\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 4.6285 - val_loss: 2.5435\n",
      "Epoch 976/1200\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 5.1648 - val_loss: 2.5383\n",
      "Epoch 977/1200\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 4.2722 - val_loss: 2.4985\n",
      "Epoch 978/1200\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 7.7437 - val_loss: 2.5301\n",
      "Epoch 979/1200\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 7.1470 - val_loss: 2.6180\n",
      "Epoch 980/1200\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 4.1449 - val_loss: 2.5206\n",
      "Epoch 981/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 4.9086 - val_loss: 2.5178\n",
      "Epoch 982/1200\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 3.1470 - val_loss: 3.2046\n",
      "Epoch 983/1200\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 3.0015 - val_loss: 1.6827\n",
      "Epoch 984/1200\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 4.8110 - val_loss: 3.0806\n",
      "Epoch 985/1200\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 4.5613 - val_loss: 2.4926\n",
      "Epoch 986/1200\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 5.0681 - val_loss: 1.9897\n",
      "Epoch 987/1200\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 12.8085 - val_loss: 1.5945\n",
      "Epoch 988/1200\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 4.4034 - val_loss: 3.0825\n",
      "Epoch 989/1200\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 3.8531 - val_loss: 2.4758\n",
      "Epoch 990/1200\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 3.0571 - val_loss: 2.4669\n",
      "Epoch 991/1200\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 3.5327 - val_loss: 2.1847\n",
      "Epoch 992/1200\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 3.2614 - val_loss: 2.6492\n",
      "Epoch 993/1200\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 6.3602 - val_loss: 2.4095\n",
      "Epoch 994/1200\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 6.0200 - val_loss: 2.3752\n",
      "Epoch 995/1200\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 6.1432 - val_loss: 2.4422\n",
      "Epoch 996/1200\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 5.1242 - val_loss: 2.2796\n",
      "Epoch 997/1200\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 13.7466 - val_loss: 2.9450\n",
      "Epoch 998/1200\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 7.7345 - val_loss: 2.7468\n",
      "Epoch 999/1200\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 3.4394 - val_loss: 2.5976\n",
      "Epoch 1000/1200\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.6262\n",
      "Epoch 1000: saving model to LSTM+BN5--2022_12_19_14_47_37.hdf5\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 3.6262 - val_loss: 2.4278\n",
      "Epoch 1001/1200\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 3.8413 - val_loss: 2.3178\n",
      "Epoch 1002/1200\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 4.8587 - val_loss: 1.9321\n",
      "Epoch 1003/1200\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 3.6128 - val_loss: 2.2519\n",
      "Epoch 1004/1200\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 12.1425 - val_loss: 2.3284\n",
      "Epoch 1005/1200\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 17.7682 - val_loss: 2.4266\n",
      "Epoch 1006/1200\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 4.5965 - val_loss: 2.3328\n",
      "Epoch 1007/1200\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 5.9415 - val_loss: 3.0033\n",
      "Epoch 1008/1200\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 3.8661 - val_loss: 1.6463\n",
      "Epoch 1009/1200\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 3.5810 - val_loss: 2.9925\n",
      "Epoch 1010/1200\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 2.9724 - val_loss: 2.3930\n",
      "Epoch 1011/1200\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 3.9150 - val_loss: 2.4178\n",
      "Epoch 1012/1200\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 4.8575 - val_loss: 2.3556\n",
      "Epoch 1013/1200\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 4.8999 - val_loss: 2.6479\n",
      "Epoch 1014/1200\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 6.3769 - val_loss: 2.3854\n",
      "Epoch 1015/1200\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 4.8837 - val_loss: 2.3747\n",
      "Epoch 1016/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 404ms/step - loss: 6.4998 - val_loss: 2.8550\n",
      "Epoch 1017/1200\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 2.8307 - val_loss: 2.6288\n",
      "Epoch 1018/1200\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 2.8793 - val_loss: 2.0696\n",
      "Epoch 1019/1200\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 3.2782 - val_loss: 2.6140\n",
      "Epoch 1020/1200\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 3.6456 - val_loss: 2.3491\n",
      "Epoch 1021/1200\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 17.4330 - val_loss: 1.8071\n",
      "Epoch 1022/1200\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 40.1395 - val_loss: 2.4566\n",
      "Epoch 1023/1200\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 5.1700 - val_loss: 1.6054\n",
      "Epoch 1024/1200\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 6.2406 - val_loss: 2.9558\n",
      "Epoch 1025/1200\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 8.9317 - val_loss: 2.3713\n",
      "Epoch 1026/1200\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 3.4226 - val_loss: 2.3584\n",
      "Epoch 1027/1200\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 2.7861 - val_loss: 2.3372\n",
      "Epoch 1028/1200\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 3.7407 - val_loss: 2.1845\n",
      "Epoch 1029/1200\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 2.8236 - val_loss: 2.4323\n",
      "Epoch 1030/1200\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 3.7044 - val_loss: 2.3358\n",
      "Epoch 1031/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 5.2484 - val_loss: 2.9026\n",
      "Epoch 1032/1200\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 9.4671 - val_loss: 2.0613\n",
      "Epoch 1033/1200\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 10.6739 - val_loss: 1.7842\n",
      "Epoch 1034/1200\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 5.7081 - val_loss: 2.4991\n",
      "Epoch 1035/1200\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 2.8471 - val_loss: 2.3287\n",
      "Epoch 1036/1200\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 3.6908 - val_loss: 2.7814\n",
      "Epoch 1037/1200\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 3.0359 - val_loss: 1.5917\n",
      "Epoch 1038/1200\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 3.4736 - val_loss: 3.1234\n",
      "Epoch 1039/1200\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 3.5779 - val_loss: 2.2134\n",
      "Epoch 1040/1200\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 3.2063 - val_loss: 2.2948\n",
      "Epoch 1041/1200\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 5.9520 - val_loss: 1.8388\n",
      "Epoch 1042/1200\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 3.6332 - val_loss: 2.1960\n",
      "Epoch 1043/1200\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 3.9056 - val_loss: 2.3635\n",
      "Epoch 1044/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 3.9321 - val_loss: 2.4395\n",
      "Epoch 1045/1200\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 3.3463 - val_loss: 2.2640\n",
      "Epoch 1046/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 2.7285 - val_loss: 1.8027\n",
      "Epoch 1047/1200\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 3.0169 - val_loss: 2.0013\n",
      "Epoch 1048/1200\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 11.2912 - val_loss: 1.9352\n",
      "Epoch 1049/1200\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 5.9919 - val_loss: 1.9911\n",
      "Epoch 1050/1200\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 24.6069 - val_loss: 2.2569\n",
      "Epoch 1051/1200\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 5.6521 - val_loss: 1.8188\n",
      "Epoch 1052/1200\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 5.2722 - val_loss: 2.7969\n",
      "Epoch 1053/1200\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 5.3550 - val_loss: 2.2523\n",
      "Epoch 1054/1200\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 2.6510 - val_loss: 1.7154\n",
      "Epoch 1055/1200\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 2.6395 - val_loss: 2.2388\n",
      "Epoch 1056/1200\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 3.8759 - val_loss: 1.9854\n",
      "Epoch 1057/1200\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 5.3993 - val_loss: 2.9180\n",
      "Epoch 1058/1200\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 12.1994 - val_loss: 2.4950\n",
      "Epoch 1059/1200\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 6.2743 - val_loss: 2.2180\n",
      "Epoch 1060/1200\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 7.3515 - val_loss: 2.2328\n",
      "Epoch 1061/1200\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 14.6224 - val_loss: 2.1360\n",
      "Epoch 1062/1200\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 2.6880 - val_loss: 2.2406\n",
      "Epoch 1063/1200\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 2.9347 - val_loss: 2.3160\n",
      "Epoch 1064/1200\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 3.5450 - val_loss: 2.2156\n",
      "Epoch 1065/1200\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 4.4605 - val_loss: 2.2117\n",
      "Epoch 1066/1200\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 3.2286 - val_loss: 1.7634\n",
      "Epoch 1067/1200\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 8.1083 - val_loss: 1.4288\n",
      "Epoch 1068/1200\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 3.5648 - val_loss: 2.3676\n",
      "Epoch 1069/1200\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 6.4565 - val_loss: 2.2040\n",
      "Epoch 1070/1200\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 11.7951 - val_loss: 2.2072\n",
      "Epoch 1071/1200\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 2.5956 - val_loss: 2.2033\n",
      "Epoch 1072/1200\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 2.6950 - val_loss: 2.6376\n",
      "Epoch 1073/1200\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 3.4932 - val_loss: 2.2707\n",
      "Epoch 1074/1200\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 4.4475 - val_loss: 2.1869\n",
      "Epoch 1075/1200\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 4.8175 - val_loss: 2.1860\n",
      "Epoch 1076/1200\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 4.9702 - val_loss: 2.0846\n",
      "Epoch 1077/1200\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 11.1103 - val_loss: 1.5134\n",
      "Epoch 1078/1200\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 6.1662 - val_loss: 2.1817\n",
      "Epoch 1079/1200\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 5.9971 - val_loss: 2.1774\n",
      "Epoch 1080/1200\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 3.3559 - val_loss: 2.1707\n",
      "Epoch 1081/1200\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 2.6005 - val_loss: 2.2609\n",
      "Epoch 1082/1200\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 3.4247 - val_loss: 2.1623\n",
      "Epoch 1083/1200\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 4.0757 - val_loss: 1.6288\n",
      "Epoch 1084/1200\n",
      "1/1 [==============================] - 1s 834ms/step - loss: 4.3466 - val_loss: 2.6599\n",
      "Epoch 1085/1200\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 5.6016 - val_loss: 2.1557\n",
      "Epoch 1086/1200\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 6.9224 - val_loss: 2.2957\n",
      "Epoch 1087/1200\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 7.8596 - val_loss: 2.0657\n",
      "Epoch 1088/1200\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 2.7960 - val_loss: 1.7137\n",
      "Epoch 1089/1200\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 4.0449 - val_loss: 2.6652\n",
      "Epoch 1090/1200\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 2.5435 - val_loss: 2.1305\n",
      "Epoch 1091/1200\n",
      "1/1 [==============================] - 1s 800ms/step - loss: 2.6046 - val_loss: 1.6218\n",
      "Epoch 1092/1200\n",
      "1/1 [==============================] - 1s 834ms/step - loss: 3.4863 - val_loss: 2.1220\n",
      "Epoch 1093/1200\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 4.2843 - val_loss: 1.9551\n",
      "Epoch 1094/1200\n",
      "1/1 [==============================] - 1s 775ms/step - loss: 3.4293 - val_loss: 2.1082\n",
      "Epoch 1095/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 591ms/step - loss: 5.0063 - val_loss: 2.1108\n",
      "Epoch 1096/1200\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 3.1724 - val_loss: 1.5786\n",
      "Epoch 1097/1200\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 11.2451 - val_loss: 1.9513\n",
      "Epoch 1098/1200\n",
      "1/1 [==============================] - 1s 586ms/step - loss: 4.2866 - val_loss: 2.2708\n",
      "Epoch 1099/1200\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 3.2903 - val_loss: 2.7688\n",
      "Epoch 1100/1200\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0436\n",
      "Epoch 1100: saving model to LSTM+BN5--2022_12_19_14_47_37.hdf5\n",
      "1/1 [==============================] - 1s 830ms/step - loss: 3.0436 - val_loss: 2.1070\n",
      "Epoch 1101/1200\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 3.7183 - val_loss: 2.7597\n",
      "Epoch 1102/1200\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 4.7829 - val_loss: 1.6777\n",
      "Epoch 1103/1200\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 3.7870 - val_loss: 2.6212\n",
      "Epoch 1104/1200\n",
      "1/1 [==============================] - 1s 886ms/step - loss: 9.7584 - val_loss: 2.0699\n",
      "Epoch 1105/1200\n",
      "1/1 [==============================] - 1s 722ms/step - loss: 4.1819 - val_loss: 2.0843\n",
      "Epoch 1106/1200\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 3.5928 - val_loss: 2.3099\n",
      "Epoch 1107/1200\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 6.1560 - val_loss: 2.6614\n",
      "Epoch 1108/1200\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 3.2469 - val_loss: 2.1559\n",
      "Epoch 1109/1200\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 2.5444 - val_loss: 1.5737\n",
      "Epoch 1110/1200\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 3.4465 - val_loss: 2.0693\n",
      "Epoch 1111/1200\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 8.2229 - val_loss: 2.3172\n",
      "Epoch 1112/1200\n",
      "1/1 [==============================] - 1s 801ms/step - loss: 3.1798 - val_loss: 2.0769\n",
      "Epoch 1113/1200\n",
      "1/1 [==============================] - 1s 919ms/step - loss: 5.7528 - val_loss: 1.4448\n",
      "Epoch 1114/1200\n",
      "1/1 [==============================] - 1s 769ms/step - loss: 59.5932 - val_loss: 2.0894\n",
      "Epoch 1115/1200\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 8.9764 - val_loss: 2.0977\n",
      "Epoch 1116/1200\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 4.9717 - val_loss: 1.9456\n",
      "Epoch 1117/1200\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 2.4917 - val_loss: 2.2269\n",
      "Epoch 1118/1200\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 2.7157 - val_loss: 2.0407\n",
      "Epoch 1119/1200\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 3.6831 - val_loss: 2.0936\n",
      "Epoch 1120/1200\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 5.0995 - val_loss: 2.0742\n",
      "Epoch 1121/1200\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 4.8096 - val_loss: 2.0729\n",
      "Epoch 1122/1200\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 6.5379 - val_loss: 2.0875\n",
      "Epoch 1123/1200\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 3.5422 - val_loss: 2.1746\n",
      "Epoch 1124/1200\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 5.0425 - val_loss: 2.0688\n",
      "Epoch 1125/1200\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 3.3584 - val_loss: 2.0641\n",
      "Epoch 1126/1200\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 3.0986 - val_loss: 2.1720\n",
      "Epoch 1127/1200\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 2.4914 - val_loss: 1.8032\n",
      "Epoch 1128/1200\n",
      "1/1 [==============================] - 1s 839ms/step - loss: 4.2973 - val_loss: 2.1436\n",
      "Epoch 1129/1200\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 18.4112 - val_loss: 2.0604\n",
      "Epoch 1130/1200\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 13.7768 - val_loss: 2.0641\n",
      "Epoch 1131/1200\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 3.9442 - val_loss: 2.5516\n",
      "Epoch 1132/1200\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 3.3794 - val_loss: 1.6647\n",
      "Epoch 1133/1200\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 4.7439 - val_loss: 1.3286\n",
      "Epoch 1134/1200\n",
      "1/1 [==============================] - 1s 746ms/step - loss: 3.2153 - val_loss: 2.1464\n",
      "Epoch 1135/1200\n",
      "1/1 [==============================] - 1s 997ms/step - loss: 2.4817 - val_loss: 2.0456\n",
      "Epoch 1136/1200\n",
      "1/1 [==============================] - 1s 774ms/step - loss: 3.0531 - val_loss: 1.4177\n",
      "Epoch 1137/1200\n",
      "1/1 [==============================] - 1s 756ms/step - loss: 3.4073 - val_loss: 1.7893\n",
      "Epoch 1138/1200\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 6.7961 - val_loss: 1.5539\n",
      "Epoch 1139/1200\n",
      "1/1 [==============================] - 1s 643ms/step - loss: 8.0860 - val_loss: 2.5337\n",
      "Epoch 1140/1200\n",
      "1/1 [==============================] - 1s 624ms/step - loss: 12.9375 - val_loss: 2.0521\n",
      "Epoch 1141/1200\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 3.8265 - val_loss: 2.1900\n",
      "Epoch 1142/1200\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 3.7792 - val_loss: 1.9548\n",
      "Epoch 1143/1200\n",
      "1/1 [==============================] - 1s 614ms/step - loss: 3.1206 - val_loss: 2.3785\n",
      "Epoch 1144/1200\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 2.9406 - val_loss: 2.1758\n",
      "Epoch 1145/1200\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 2.6304 - val_loss: 2.0301\n",
      "Epoch 1146/1200\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 4.0239 - val_loss: 2.6502\n",
      "Epoch 1147/1200\n",
      "1/1 [==============================] - 1s 649ms/step - loss: 4.1763 - val_loss: 2.0276\n",
      "Epoch 1148/1200\n",
      "1/1 [==============================] - 1s 634ms/step - loss: 4.1332 - val_loss: 1.3934\n",
      "Epoch 1149/1200\n",
      "1/1 [==============================] - 1s 749ms/step - loss: 9.4576 - val_loss: 2.0228\n",
      "Epoch 1150/1200\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 6.7933 - val_loss: 2.0314\n",
      "Epoch 1151/1200\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 2.7418 - val_loss: 1.4067\n",
      "Epoch 1152/1200\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 2.6932 - val_loss: 2.1598\n",
      "Epoch 1153/1200\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 2.4277 - val_loss: 1.3956\n",
      "Epoch 1154/1200\n",
      "1/1 [==============================] - 1s 746ms/step - loss: 3.0664 - val_loss: 2.4840\n",
      "Epoch 1155/1200\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 5.5020 - val_loss: 2.0103\n",
      "Epoch 1156/1200\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 2.5517 - val_loss: 2.0050\n",
      "Epoch 1157/1200\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 9.5624 - val_loss: 2.4839\n",
      "Epoch 1158/1200\n",
      "1/1 [==============================] - 1s 748ms/step - loss: 7.8251 - val_loss: 1.9230\n",
      "Epoch 1159/1200\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 3.8216 - val_loss: 1.5195\n",
      "Epoch 1160/1200\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 4.5600 - val_loss: 1.9883\n",
      "Epoch 1161/1200\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 3.2365 - val_loss: 1.9830\n",
      "Epoch 1162/1200\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 2.4064 - val_loss: 1.4208\n",
      "Epoch 1163/1200\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 2.3177 - val_loss: 1.9160\n",
      "Epoch 1164/1200\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 3.9918 - val_loss: 1.9718\n",
      "Epoch 1165/1200\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 3.8357 - val_loss: 1.9619\n",
      "Epoch 1166/1200\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 3.9136 - val_loss: 1.4849\n",
      "Epoch 1167/1200\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 4.5483 - val_loss: 2.3474\n",
      "Epoch 1168/1200\n",
      "1/1 [==============================] - 1s 978ms/step - loss: 9.2138 - val_loss: 1.9681\n",
      "Epoch 1169/1200\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 2.3014 - val_loss: 1.8871\n",
      "Epoch 1170/1200\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 9.6234 - val_loss: 1.9691\n",
      "Epoch 1171/1200\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 2.5416 - val_loss: 1.9655\n",
      "Epoch 1172/1200\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 2.2755 - val_loss: 2.0092\n",
      "Epoch 1173/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 598ms/step - loss: 3.4417 - val_loss: 1.9578\n",
      "Epoch 1174/1200\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 4.6626 - val_loss: 1.5721\n",
      "Epoch 1175/1200\n",
      "1/1 [==============================] - 1s 843ms/step - loss: 3.5563 - val_loss: 1.9517\n",
      "Epoch 1176/1200\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 3.7336 - val_loss: 1.9502\n",
      "Epoch 1177/1200\n",
      "1/1 [==============================] - 1s 855ms/step - loss: 6.5818 - val_loss: 1.9312\n",
      "Epoch 1178/1200\n",
      "1/1 [==============================] - 1s 783ms/step - loss: 3.8917 - val_loss: 2.1947\n",
      "Epoch 1179/1200\n",
      "1/1 [==============================] - 1s 614ms/step - loss: 3.5496 - val_loss: 2.0196\n",
      "Epoch 1180/1200\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 2.6328 - val_loss: 1.9289\n",
      "Epoch 1181/1200\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 2.3080 - val_loss: 2.5143\n",
      "Epoch 1182/1200\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 2.8765 - val_loss: 1.4512\n",
      "Epoch 1183/1200\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 5.6506 - val_loss: 2.3857\n",
      "Epoch 1184/1200\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 5.2052 - val_loss: 1.9187\n",
      "Epoch 1185/1200\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 2.7080 - val_loss: 1.9174\n",
      "Epoch 1186/1200\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 11.0882 - val_loss: 1.4659\n",
      "Epoch 1187/1200\n",
      "1/1 [==============================] - 1s 659ms/step - loss: 6.5280 - val_loss: 2.1181\n",
      "Epoch 1188/1200\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 3.4181 - val_loss: 2.4214\n",
      "Epoch 1189/1200\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 2.6081 - val_loss: 1.9943\n",
      "Epoch 1190/1200\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 2.5826 - val_loss: 1.9010\n",
      "Epoch 1191/1200\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 3.4022 - val_loss: 1.8978\n",
      "Epoch 1192/1200\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 11.3646 - val_loss: 1.2221\n",
      "Epoch 1193/1200\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 2.5596 - val_loss: 2.0278\n",
      "Epoch 1194/1200\n",
      "1/1 [==============================] - 1s 660ms/step - loss: 3.6018 - val_loss: 1.2983\n",
      "Epoch 1195/1200\n",
      "1/1 [==============================] - 1s 852ms/step - loss: 3.7614 - val_loss: 1.8844\n",
      "Epoch 1196/1200\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 3.3063 - val_loss: 2.0169\n",
      "Epoch 1197/1200\n",
      "1/1 [==============================] - 1s 793ms/step - loss: 3.7070 - val_loss: 2.0810\n",
      "Epoch 1198/1200\n",
      "1/1 [==============================] - 1s 747ms/step - loss: 2.2517 - val_loss: 1.2148\n",
      "Epoch 1199/1200\n",
      "1/1 [==============================] - 1s 656ms/step - loss: 2.8304 - val_loss: 2.4533\n",
      "Epoch 1200/1200\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.1627\n",
      "Epoch 1200: saving model to LSTM+BN5--2022_12_19_14_47_37.hdf5\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 5.1627 - val_loss: 1.8746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f67902e2130>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_str='%Y_%m_%d_%H_%M_%S'\n",
    "\n",
    "ada = Adadelta()\n",
    "\n",
    "early_stop = EarlyStopping(monitor='loss', min_delta=0.001, patience=4, mode='min', verbose=1)\n",
    "checkpoint = ModelCheckpoint(filepath=f'LSTM+BN5--{datetime.now().strftime(time_str)}.hdf5', monitor='loss', verbose=10, mode='min', period=100)\n",
    "# the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=ada)\n",
    "\n",
    "# captures output of softmax so we can decode the output during visualization\n",
    "model.fit_generator(generator=tiger_train.next_batch(),\n",
    "                    steps_per_epoch=int(tiger_train.n / batch_size),\n",
    "                    epochs=1200,\n",
    "                    callbacks=[checkpoint],\n",
    "                    validation_data=tiger_val.next_batch(),\n",
    "                    validation_steps=int(tiger_val.n / val_batch_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
